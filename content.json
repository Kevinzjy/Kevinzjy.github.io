{"meta":{"title":"Kevinzjy's Blog","subtitle":"生信狗的个人小站","description":"Kevinzjy","author":"Jinyang Zhang","url":"https://kevinzjy.github.io"},"pages":[{"title":"","date":"2020-12-26T08:24:26.689Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"404.html","permalink":"https://kevinzjy.github.io/404.html","excerpt":"","text":""},{"title":"About","date":"2017-03-24T14:13:02.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"about/index.html","permalink":"https://kevinzjy.github.io/about/index.html","excerpt":"","text":"Stay hungry, Stay foolish Personal Information Kevinzjy PKU 生科狗，UCAS搬砖ing E-MAIL: kevinzjy1997@gmail.com Education Beijing Institutes of Life Sciences, Chinese Academy of Sciences, Ph.D., Genetics, 2015-present Peking University, B.S., Life Siences, 2011-2015 Publications Zhang J, Chen S, Yang J &amp; Zhao F. Accurate quantification of circular RNAs identifies extensive circular isoform switching events. Nature Communications, 2019 (accepted). Ji P#, Wu W#, Chen S#, Zheng Y, Zhou L, Zhang J, Cheng H, Yan J, Zhang S, Yang P &amp; Zhao F. Expanded expression landscape and prioritization of circular RNAs in mammals. Cell Reports, 2019, 26:3444-3460. Gao Y, Zhang J &amp; Zhao F. Circular RNA identification based on multiple seed matching. Briefing in Bioinformatics 2017, DOI: 10.1093/bib/bbx014. Gao Y#, Wang J#, Zheng Y#, Zhang J, Chen S &amp; Zhao F. Comprehensive identification of internal structure and alternative splicing events in circular RNAs. Nature Communications 2016, 18(7):2143-2158."},{"title":"Categories","date":"2017-03-24T15:57:01.000Z","updated":"2020-12-26T08:24:26.697Z","comments":false,"path":"categories/index.html","permalink":"https://kevinzjy.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-03-24T15:56:54.000Z","updated":"2020-12-26T08:24:26.697Z","comments":false,"path":"tags/index.html","permalink":"https://kevinzjy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"CentOS6 开机自动运行脚本","slug":"crontab","date":"2020-12-26T08:19:55.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/12/26/crontab/","link":"","permalink":"https://kevinzjy.github.io/2020/12/26/crontab/","excerpt":"","text":"为了让安装的 Mysql 和 Tomcat6 服务可以重启后自动运行，可以利用 crontab 命令指定开机后运行自定义脚本 脚本 /root/restart_mysql.sh 内容 123#!/bin/sh/etc/init.d/mysqld start/usr/local/src/tomcat6/bin/startup.sh 使用 crontab -e 命令对定时任务进行编辑，增加一行 1@reboot /root/restart_mysql.sh 这样可以实现每次重启后自动运行脚本中的任务，而不用手动开启服务","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"硬盘报错修复","slug":"fsck","date":"2020-12-07T08:28:43.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/12/07/fsck/","link":"","permalink":"https://kevinzjy.github.io/2020/12/07/fsck/","excerpt":"","text":"Linux 开机出现硬盘报错，自动进入恢复模式。可以使用 fsck 命令对硬盘错误进行修复 12345678# 检查硬盘错误fsck -y# 重新挂载根目录mount -o remount,rw /# 重新启动reboot","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"rsync 拷贝指定拓展名文件","slug":"Rsync","date":"2020-07-28T01:57:06.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/07/28/Rsync/","link":"","permalink":"https://kevinzjy.github.io/2020/07/28/Rsync/","excerpt":"","text":"使用 rsync 命令拷贝目录下所有具有指定拓展名的文件（*.fastq.gz, *.fq.gz) 1rsync -avP --include=\"*/\" --include=\"*.fq.gz\" --include=\"*.fastq.gz\" --exclude=\"*\" src_dir tgt_dir","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"}]},{"title":"Proxmox VE 环境安装","slug":"PVE_installation","date":"2020-05-24T03:48:23.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/05/24/PVE_installation/","link":"","permalink":"https://kevinzjy.github.io/2020/05/24/PVE_installation/","excerpt":"这两天在家里尝试了下 Proxmox 的安装，记录一下需要注意的内容 安装过程参考: https://pve.proxmox.com/wiki/Installation，需要注意网络配置静态IP","text":"这两天在家里尝试了下 Proxmox 的安装，记录一下需要注意的内容 安装过程参考: https://pve.proxmox.com/wiki/Installation，需要注意网络配置静态IP 更换系统自带的 vim-tiny 为 vim12apt remove vim-tinyapt install vim 更换免费源注释掉 /etc/apt/sources.list.d/pve-enterprise.list 中 enterprise 源内容 1#deb https://enterprise.proxmox.com/debian/pve buster pve-enterprise 修改 /etc/apt/sources.list ，加入免费源 123# PVE pve-no-subscription repository provided by proxmox.com,# NOT recommended for production usedeb http://download.proxmox.com/debian/pve buster pve-no-subscription 更新源 12apt updateapt upgrade 去除付费提示123cd /usr/share/javascript/proxmox-widget-toolkitcp proxmoxlib.js proxmoxlib.js.bakvim proxmoxlib.js 将 data.status !== ‘Active’ 替换为 false 1234393c393&lt; if (data.status !== &apos;Active&apos;) &#123;---&gt; if (false) &#123; 重启 PVE 网页服务 1systemctl restart pveproxy Comman + Shift + R 刷新页面缓存之后，订阅提示就会消失了 其他设置12apt install ntp ntpdatentpdate -u ntp.aliyun.com 虚拟机 ISO 文件存放位置1/var/lib/vz/template/iso","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"Git 如何配置 gitignore 生效","slug":"gitignore","date":"2020-04-12T04:15:22.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/04/12/gitignore/","link":"","permalink":"https://kevinzjy.github.io/2020/04/12/gitignore/","excerpt":"","text":"在 git 项目仓库中，配置 .gitignore 文件时，需要重新添加所有文件使得增加的规则生效 12345678# Remove cached filesgit rm -r --cached .# Add everything backgit add .# Commit changesgit commit -m &quot;update .gitignore&quot;","categories":[{"name":"git","slug":"git","permalink":"https://kevinzjy.github.io/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://kevinzjy.github.io/tags/git/"}]},{"title":"ssh 跳过身份验证","slug":"ssh_known_hosts","date":"2020-03-09T11:30:42.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/03/09/ssh_known_hosts/","link":"","permalink":"https://kevinzjy.github.io/2020/03/09/ssh_known_hosts/","excerpt":"最近遇到了一个奇怪的情况，有用户反映从在服务器上无法用scp命令向其他所的服务器拷贝数据，报错提示 REMOTE HOST IDENTIFICATION HAS CHANGED!，可能是身份验证出现了问题。","text":"最近遇到了一个奇怪的情况，有用户反映从在服务器上无法用scp命令向其他所的服务器拷贝数据，报错提示 REMOTE HOST IDENTIFICATION HAS CHANGED!，可能是身份验证出现了问题。 问题1根据提示，报错原因是远程服务器 ECDSA key 发生了变化，和 ~/.ssh/known_hosts 中记录的 key 不同。因此删除已记录的 key 之后，应该就可以重新登录。 12345678910111213141516[user1@manager ~]$ scp src_data.fq.gz CASPMI@remote_server:/remote/data/dir@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host is00:25:2c:82:e2:51:18:34:da:ab:56:a4:ad:cc:a6:19.Please contact your system administrator.Add correct host key in /home/user1/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /home/user1/.ssh/known_hosts:2Password authentication is disabled to avoid man-in-the-middle attacks.Keyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.Permission denied (publickey,gssapi-with-mic,password,hostbased).lost connection 在删除了 ~/.ssh/known_hosts 的第二行记录后，果然可以正常scp拷贝数据了 问题2过了几个小时，该用户发现又开始出现相同报错，同时反映需要登录的服务器是使用动态验证码+验证卡登录。因此猜测远程服务器可能在不断更新 Host key 。。。因此之前的方法只能暂时解决问题。 最终解决方案：编辑 ssh 配置文件 ~/.ssh/config，跳过 Host key 的验证 123Host remote_server StrictHostKeyChecking no UserKnownHostsFile=/dev/null 这样配置后，不管远程服务器怎么更新，都不需要进行 known_hosts 的检查了，成功解决。","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"上传 python 模块到 pypi.org","slug":"Pypi_deploy","date":"2020-03-04T10:55:20.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2020/03/04/Pypi_deploy/","link":"","permalink":"https://kevinzjy.github.io/2020/03/04/Pypi_deploy/","excerpt":"为了方便软件安装和调试，这次在更新 CIRIquant_v1.0.1 版本的同时，尝试了将软件发布在 pypi.org 平台。这样通过一条pip 命令就可以实现软件和依赖的安装了","text":"为了方便软件安装和调试，这次在更新 CIRIquant_v1.0.1 版本的同时，尝试了将软件发布在 pypi.org 平台。这样通过一条pip 命令就可以实现软件和依赖的安装了 准备工作 python 模块中已编写好的 setup.py 安装所需模块 12pip install wheel setuptoolspip install twine 打包脚本1python setup.py sdist bdist_wheel 打包完成后，会在 dist/ 文件夹下产生两个打包好的压缩包, 分别对应 setuptools 和 easy_install 两种安装方式 测试脚本1twine check dist/* 这一步目的是为了检查脚本是否符合规范 预发布测试1twine upload --repository-url https://test.pypi.org/legacy/ dist/* test.pypi.org 是一个与 pypi.org 互相独立的平台，可以用于在正式版本发布前进行测试，这里进行的修改不会影响到 pypi.org 上的内容 上传到 pypi.org1twine upload dist/* 根据提示输入用户名/密码后，即可成功发布软件到 pypi.org 发布成功后，就可以直接使用 pip install 命令来安装我们的软件了","categories":[{"name":"Python","slug":"python","permalink":"https://kevinzjy.github.io/categories/python/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Python","slug":"Python","permalink":"https://kevinzjy.github.io/tags/Python/"}]},{"title":"CentOS7 安装 pdftk","slug":"CentOS_pdftk","date":"2019-11-10T10:54:15.000Z","updated":"2020-12-26T08:24:26.697Z","comments":true,"path":"2019/11/10/CentOS_pdftk/","link":"","permalink":"https://kevinzjy.github.io/2019/11/10/CentOS_pdftk/","excerpt":"我们在文章投稿的时候，会需要提供一个包括所有 Figure 的 pdf 文件。此时，pdftk 这个工具可以帮助我们快速合并已有的 pdf，并生成一个无压缩的合并文件。","text":"我们在文章投稿的时候，会需要提供一个包括所有 Figure 的 pdf 文件。此时，pdftk 这个工具可以帮助我们快速合并已有的 pdf，并生成一个无压缩的合并文件。 为什么使用 pdftk一开始，我是使用了 ghostscript 进行 pdf 合并 12345678910gs -dNOPAUSE \\ -dColorConversionStrategy=/LeaveColorUnchanged \\ -dEncodeColorImages=false \\ -dEncodeGrayImages=false \\ -dEncodeMonoImages=false \\ -sDEVICE=pdfwrite \\ -dPDFSETTINGS=/prepress \\ -sOUTPUTFILE=converted.pdf \\ -dBATCH \\ Fig1.pdf Fig2.pdf Fig3.pdf Fig4.pdf Fig5.pdf Fig6.pdf 然而，从文件的大小来和合并之后的画质来看， ghostscript 仍然对我的图像进行了压缩，效果比较糟糕。因此，我选择了 pdftk 来直接合并文件 pdftk 安装在 Centos 6 系统中，pdftk 直接提供了 RPM 的安装方式。然而我使用的是 WSL 中的 CentOS 7 因此需要额外进行一些操作，才可以成功使用 pdftk 首先，我们需要安装一些 pdftk 需要的依赖库 1sudo yum install gcc gcc-c++ libXrandr gtk2 libXtst libart_lgpl pdftk 需要的 libgcj 并不在标准库中，因此我们需要下载 rpm 文件到本地安装 12wget http://li.nux.ro/download/nux/dextop/el7/x86_64//libgcj-4.8.2-16.el7.i686.rpmsudo rpm -ivh ./libgcj-4.8.2-16.el7.i686.rpm 最后，安装 pdftk 的本体 1sudo yum localinstall https://www.linuxglobal.com/static/blog/pdftk-2.02-1.el7.x86_64.rpm 使用 pdftk 合并 pdf1pdftk ./Fig1.pdf ./Fig2.pdf ./Fig3.pdf ./Fig4.pdf ./Fig5.pdf ./Fig6.pdf cat output converted.pdf 经过对比发现，ghostscript 文件压缩之后的大小为 7M 左右，而 pdftk 合并之后的文件大小在 14M，足足差了一倍。可能在 ghostscript 也可以通过增加一些参数指定不进行压缩，但是在简单的 pdf 合并任务上，pdftk 还是更加合适的。","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"CentOS7 调整 lvm 分区大小","slug":"CentOS_lvm","date":"2019-07-22T08:06:03.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/07/22/CentOS_lvm/","link":"","permalink":"https://kevinzjy.github.io/2019/07/22/CentOS_lvm/","excerpt":"Centos7 系统在安装时，会默认使用 lvm 创建三个逻辑卷 Volume FS Mount Point Size /dev/centos/home xfs /home 157.20 GB /dev/centos/root xfs /root 50.00 GB /dev/centos/swap 4.00 GB 默认分配给挂载点 /home 的空间大小较大，而由于在集群中，用户的目录都在存储阵列上，并且 root 账户拥有 /root 目录，因此 /home 目录几乎不会使用到，因此需要在安装时调整默认的分区大小 同时我们可以看到，交换空间分区 swap 的大小只有 4G， 可能是安装时考虑到节点内存较大 (128GB)，因此默认没有更大的分配交换空间。然而经过实际使用证明，swap 分区的大小是远远不够的，很多软件会在使用内存的同时使用swap空间，并且当交换空间占满后，系统的IO性能会有所降低。 由于之前节点重装时，没有考虑到以上两点，因此现在需要对 lvm 分区大小进行调整。所以我准备使用 lvm 管理命令结合 system-storage-manager 软件，实现对 /home 分区空间的缩减，并重新分配到 Swap 交换空间以及 / 根目录中","text":"Centos7 系统在安装时，会默认使用 lvm 创建三个逻辑卷 Volume FS Mount Point Size /dev/centos/home xfs /home 157.20 GB /dev/centos/root xfs /root 50.00 GB /dev/centos/swap 4.00 GB 默认分配给挂载点 /home 的空间大小较大，而由于在集群中，用户的目录都在存储阵列上，并且 root 账户拥有 /root 目录，因此 /home 目录几乎不会使用到，因此需要在安装时调整默认的分区大小 同时我们可以看到，交换空间分区 swap 的大小只有 4G， 可能是安装时考虑到节点内存较大 (128GB)，因此默认没有更大的分配交换空间。然而经过实际使用证明，swap 分区的大小是远远不够的，很多软件会在使用内存的同时使用swap空间，并且当交换空间占满后，系统的IO性能会有所降低。 由于之前节点重装时，没有考虑到以上两点，因此现在需要对 lvm 分区大小进行调整。所以我准备使用 lvm 管理命令结合 system-storage-manager 软件，实现对 /home 分区空间的缩减，并重新分配到 Swap 交换空间以及 / 根目录中 在执行下文所述操作之前，需要确定节点上没有正在运行的任务 准备工作先将节点下线，防止有任务出现1pbsnodes -o node5 下载 system-storage-manager1yumdownloader --resolve --downloadonly --downloaddir=/dir/to/download system-storage-manager-0.4-8.el7.noarch.rpm 安装 system-storage-manager1rpm -ivh system-storage-manager-0.4-8.el7.noarch.rpm 1234警告：system-storage-manager-0.4-8.el7.noarch.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY准备中... ################################# [100%]正在升级/安装... 1:system-storage-manager-0.4-8.el7 ################################# [100%] 关闭 SWAP 分区1swapoff -a 卸载 /home 分区如果 /home 分区内有用户目录，则需要先备份到其他位置，等调整完毕后，拷贝回 /home 目录即可 1umount /home 使用 system-storage-manager 查看 lvm 分区情况ssm list 1234567891011121314151617181920212223242526----------------------------------------------------------------Device Free Used Total Pool Mount point----------------------------------------------------------------/dev/loop0 100.00 GB/dev/loop1 2.00 GB/dev/md126p1 200.00 MB /boot/efi/dev/md126p2 1.00 GB /boot/dev/md126p3 0.00 KB 211.20 GB 211.20 GB centos/dev/sda 0.00 KB 212.40 GB 223.57 GB/dev/sdb 0.00 KB 212.40 GB 223.57 GB--------------------------------------------------------------------------------------------------------------------Pool Type Devices Free Used Total----------------------------------------------------centos lvm 1 0.00 KB 211.20 GB 211.20 GB-------------------------------------------------------------------------------------------------------------------------------------------Volume Pool Volume size FS FS size Free Type Mount point---------------------------------------------------------------------------------------/dev/centos/root centos 50.00 GB xfs 49.98 GB 48.67 GB linear //dev/centos/swap centos 4.00 GB linear/dev/centos/home centos 157.20 GB xfs 157.12 GB 157.12 GB linear /home/dev/md126 md 212.40 GB raid1/dev/md126p1 200.00 MB vfat /boot/efi/dev/md126p2 1.00 GB xfs 1014.00 MB 875.35 MB /boot--------------------------------------------------------------------------------------- 释放 /home 空间删除 /dev/centos/home 逻辑卷1ssm remove /dev/centos/home 12Do you really want to remove active logical volume centos/home? [y/n]: y Logical volume &quot;home&quot; successfully removed 增加 SWAP 空间容量增加 /dev/centos/swap 逻辑卷容量1ssm resize -s +28G /dev/centos/swap 12Size of logical volume centos/swap changed from 4.00 GiB (1024 extents) to 32.00 GiB (8192 extents).Logical volume centos/swap successfully resized. 重设 SWAP 空间大小1mkswap /dev/centos/swap 123mkswap: /dev/centos/swap: warning: wiping old swap signature.正在设置交换空间版本 1，大小 = 33554428 KiB无标签，UUID=f235320f-7bfd-4f58-8a0c-15dddb935624 启用 SWAP1swapon -a 查看 SWAP 空间容量1free -m 123 total used free shared buff/cache availableMem: 128652 2411 124346 26 1894 125328Swap: 32767 0 32767 增加根目录 / 容量增加 /dev/centos/root 逻辑卷容量1lvresize -l +100%FREE /dev/centos/root 12Size of logical volume centos/root changed from 50.00 GiB (12800 extents) to &lt;179.20 GiB (45875 extents).Logical volume centos/root successfully resized. / 使用的 XFS 文件系统，需要手动扩容，否则分配的容量仍然无法使用1xfs_growfs /dev/centos/root 12345678910meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=3276800 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0data = bsize=4096 blocks=13107200, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal bsize=4096 blocks=6400, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0data blocks changed from 13107200 to 46976000 修改其他配置调整默认挂载选项编辑 /etc/fstab，删除文件内这一行 1/dev/mapper/centos-home /home xfs defaults 0 0 测试挂载文件内容是否正确1mount -a 节点上线1pbsnodes -c node5 参考资料[1]. https://blog.csdn.net/shenyue_sam/article/details/77175637[2]. https://blog.csdn.net/yexiangCSDN/article/details/83182259","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"CentOS7 集群配置 Docker","slug":"CentOS_Docker","date":"2019-06-15T08:57:39.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/06/15/CentOS_Docker/","link":"","permalink":"https://kevinzjy.github.io/2019/06/15/CentOS_Docker/","excerpt":"集群中 Docker 的安装和配置","text":"集群中 Docker 的安装和配置 Docker 安装12# 安装 Docker-CErpm -ivh --force /histor/public/yum/docker/* Docker 的启动12345678# 启动 Dockersystemctl start docker# 查看 docker 配置docker info# 运行测试程序docker run hello-world Docker更改安装位置12345678# 停止 Docker 服务systemctl stop docker# 创建配置文件的目录mkdir -p /etc/systemd/system/docker.service.d# 编辑配置文件vi /etc/systemd/system/docker.service.d/docker-storage.conf 通过配置文件指定 docker 存储文件夹 123[Service]ExecStart=ExecStart=/usr/bin/dockerd -H fd:// --data-root /histor/public/docker/node142 编辑 /etc/docker/daemon.json，更改 Docker 使用的存储驱动 123&#123; \"storage-driver\": \"devicemapper\"&#125; 保存后，重新启动 Docker 服务 12systemctl daemon-reloadsystemctl start docker 运行 docker-info 即可看到 Docker 的安装位置已经发生了变化 1Docker Root Dir: /histor/public/docker/login2 给非root用户授权，可以使用 Docker修改 /usr/lib/systemd/system/docker.socket 内容中的 SocketGroup，设为 docker 用户组 123456789101112[Unit]Description=Docker Socket for the APIPartOf=docker.service[Socket]ListenStream=/var/run/docker.sockSocketMode=0660SocketUser=rootSocketGroup=docker[Install]WantedBy=sockets.target 增加 docker 用户组 1groupadd docker 给用户授权 1usermod -aG docker zhangjy 计算节点离线安装镜像12345678# 下载镜像docker pull tensorflow/tensorflow# 将下载的镜像打包到文件docker save -i /histor/public/docker/save/tensorflow.tar tensorflow/tensorflow# 切到计算节点，进行安装docker load /histor/public/docker/save/tensorflow.tar","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"CentOS7 配置 Torque + MAUI 作业调度系统","slug":"CentOS_Gridview","date":"2019-06-14T04:01:20.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/06/14/CentOS_Gridview/","link":"","permalink":"https://kevinzjy.github.io/2019/06/14/CentOS_Gridview/","excerpt":"前两天曙光的 Gridview 管理系统配置出现了问题，导致管理节点无法正常使用。因此重新配置了一套 Torque 管理系统，正好一起配置新重装的 CentOS7 节点","text":"前两天曙光的 Gridview 管理系统配置出现了问题，导致管理节点无法正常使用。因此重新配置了一套 Torque 管理系统，正好一起配置新重装的 CentOS7 节点 服务器节点系统重装CentOS 7.6 镜像位置1node71:/root/packages/CentOS-7-x86_64-DVD-1810.iso 在 Linux 下制作 CentOS7 安装盘在 node71 上插入安装使用的U盘或者移动硬盘，根据盘符将安装镜像写入设备 12# 将系统安装镜像写入 /dev/sdcsudo dd if=/root/packages/CentOS-7-x86_64-DVD-1810.iso of=/dev/sdc 在需要安装的节点上，插入安装盘。重启节点即可进入安装界面。 给安装完成的 CentOS 配置网络网卡配置文件在 /etc/sysconfig/network-scripts 文件夹，根据其他机器的配置，修改配置文件，一般为 ifcfg-eth 或者 ifcfg-enp 开头，对应不同的网卡设备名称 ifcfg-enp4s0f01234DEVICE=enp4s0f0BOOTPROTO=staticONBOOT=noTYPE=Ethernet ifcfg-enp4s0f11234567DEVICE=enp4s0f1BOOTPROTO=noneONBOOT=yesTYPE=EthernetIPV6INIT=noIPADDR=11.11.11.3NETMASK=255.255.0.0 ifcfg-eth012345TYPE=EthernetBOOTPROTO=staticONBOOT=yesIPADDR=192.168.0.143NETMASK=255.255.255.0 修改完网卡配置后，重启网络服务，即可通过 ssh 登录计算节点进行后续的配置 1service network restart 计算节点基础配置设置 host将登录节点的 /etc/hosts 文件同步 12# 登录节点进行操作scp /etc/hosts root@node111:/etc/hosts 设置 ssh 免密码登录方法一： 可以复制登录节点的ssh配置文件，实现节点之间的登录 12# 登录节点进行操作rsync -avP /root/.ssh/* root@node143:/root/.ssh 方法二： 重新配置 ssh 123456# 登录节点进行操作# 如果登录节点也是重新安装的系统，需要先生成 ssh 秘钥ssh-keygen# 将登录节点的秘钥配置上传到 node111 中ssh-copyid node111 设置中文支持修改 /etc/profile 12export LANG=\"zh_CN.UTF-8\"export LC_ALL=\"zh_CN.UTF-8\" 限制ssh 登录目前采用的最简单的方法，直接从 sshd 服务配置上对用户进行限制 配置文件 /etc/ssh/sshd_config 根据需求增加如下内容 计算节点 1AllowUsers root # 只允许 root 账户登录 管理节点 1PermitRootLogin no # 禁止 root 账户登录 关闭 SELINUX关闭SELINUX，否则存储挂载时候会有权限问题 1sed -i s/SELINUX=enforcing/SELINUX=disabled/ /etc/selinux/config 安装和配置存储服务在管理节点下载软件安装包常用软件已经下载到 /root/download 12345# 将 git 和其依赖的软件包下载到指定文件夹yumdownloader --destdir=/histor/public/rpm/git git# 在指定节点批量安装软件ssh root@node111 \"rpm -ivh /histor/public/rpm/git/*.rpm\" 通过shell脚本循环批量安装 12345# 在 node140-node160 上批量指定命令for i in `seq 140 160`do ssh root@node$&#123;i&#125; \"rpm -ivh /histor/public/rpm/git/*.rpm\"done astor 挂载目前没有使用 icfs-fuse 客户端，而是直接使用了 nfs 格式进行挂载，对于新装的系统，需要下载 nfs-utils 软件 编辑 /etc/rc.local 文件 1mount -t nfs -o vers=3 192.168.0.226:/. /astor/ 赋予执行权限，防止开机不能自动运行1chmod +x /etc/rc.d/rc.local histor 挂载驱动程序位于 /root/Leo-xd-clt-as7.6-64-20180731，挂载命令为 /root/Leo-xd-clt-as7.6-64-20180731/LeoFS.192.168.0.245 123456789# 同步驱动rsync -avP /root/Leo-xd-clt-as7.6-64-20180731 node111:/root/Leo-xd-clt-as7.6-64-20180731# 在计算节点cp -r /root/Leo-xd-clt-as7.6-64-20180731/LeoCluster /LeoCluster# 配置自启动挂载cp /root/Leo-xd-clt-as7.6-64-20180731/LeoFS.192.168.0.245 /etc/init.d/LeoFS.192.168.0.245chkconfig LeoFS.192.168.0.245 start NTFS 硬盘挂载需要下载 ntfs-3g 和 ntfsprogs 软件 12mkdir zhaotmpmount -t ntfs /zhaotmp /dev/sdc1 用户信息配置用户配置文件包括四个: 1234/etc/passwd/etc/group/etc/shadow/etc/gshadow 将四个文件中需要配置的内容拷贝到节点上对应的文件内即可 PBS的安装和配置计算节点 PBS 安装torque 安装文件位于 /root/torque-4.2.9 123456789101112131415161718192021222324cd /root/torque-4.2.9# 在计算节点创建安装文件夹ssh node111 &quot;mkdir -p /root/torque4&quot;# 拷贝安装文件到计算节点scp torque-package-&#123;mom,clients&#125;-linux-x86_64.sh node111:/root/torque4scp contrib/init.d/&#123;pbs_mom,trqauthd&#125; node1:/etc/init.d/# 计算节点安装客户端./torque-package-clients-linux-x86_64.sh --install ./torque-package-mom-linux-x86_64.sh --install # 配置环境，编辑/var/spool/torque/mom_priv/config$pbsserver node71$logevent 225$spool_as_final_name true # 日志直接保存到最终位置# 计算节点启动服务for i in pbs_mom trqauthd; do service $i start; done# 配置开机启动chkconfig pbs_mom onchkconfig trqauthd on 将 torque 文件夹加入系统环境变量 编辑 /etc/profile，在文件末尾加入两行 12TORQUE=/usr/local/torque-4.2.9export PATH=$PATH:/usr/local/torque-4.2.9/bin:/usr/local/torque-4.2.9/sbin 在管理节点增加新节点配置文件位置 /var/spool/torque/server_priv 12#指定节点名称，可用核心数，分组名称node111 np=28 GPUfat 重启 PBS_server 使得配置信息生效 1service pbs_server restart 可以使用 pbsnodes 命令查看已经配置好的节点列表 12345# 列出所有节点信息pbsnodes# 单独查看 node111pbsnodes node111 123456789node111 state = free np = 28 properties = GPUfat ntype = cluster jobs = 0/504.node71 status = rectime=1560483848,varattr=,jobs=504.node71,state=free,netload=783666799,gres=,loadave=0.04,ncpus=28,physmem=794154304kb,availmem=821029292kb,totmem=826922296kb,idletime=50234,nusers=1,nsessions=1,sessions=11595,uname=Linux node111 2.6.32-431.el6.x86_64 #1 SMP Sun Nov 10 22:19:54 EST 2013 x86_64,opsys=linux mom_service_port = 15002 mom_manager_port = 15003 管理节点增加队列使用 qmgr 命令对队列信息进行配置 1234567891011qmgr -c 'p s' # 输出当前队列配置qmgr -c 'create queue middle' # 新增队列middleqmgr -c 'set queue middle queue_type = Execution'qmgr -c 'set queue middle resources_default.neednodes = middle' # 给队列分配分组为 middle 的节点qmgr -c 'set queue middle resources_default.walltime = 1200:00:00' # 默认 walltimeqmgr -c 'set queue middle enabled = True' # 启用队列qmgr -c 'set queue middle started = True' # 队列可以排队qmgr -c \"set queue middle acl_groups=zhaolab\" # 限制特定用户组可以使用队列qmgr -c \"set queue middle acl_group_sloppy=true\" # false 只查询用户的默认用户组; true: 查询用户所属的所有用户组qmgr -c \"set queue middle acl_hosts=node71\" # 限制可以投递任务的节点 其他设置可以参考 http://docs.adaptivecomputing.com/torque/3-0-5/4.1queueconfig.php MAUI 修改用户资源限额配置文件地址 /usr/local/maui/maui.cfg 12345# 默认用户限制USERCFG[DEFAULT] MAXJOB=40 MAXPROC=80 MAXNODE=20# 对 jipfnew 账户单独进行设置USERCFG[jipfnew] MAXJOB=100 MAXPROC=300 MAXNODE=20 修改完配置后，重启 MAUI 服务使配置生效 1service maui restart 安全设置管理节点禁止其他用户切换到 root 账户添加管理员到 wheel 用户组 12usermod -G wheel adminid admin 使用 id 命令可以查看 admin 账户的 id 和 group 信息 1uid=1000(admin) gid=1000(admin) groups=1000(admin),10(wheel) 修改 /etc/pam.d/su，将这行的注释去掉，使得只有 wheel 组的账户可以使用 su 命令切换到 root 账户 1auth required pam_wheel.so use_uid 管理节点禁止其他用户登录编辑PAM配置文件 /etc/security/access.conf 123+ : root : 192.168.0. 11.11.11. # 允许内网 root 账户登录- : root : ALL # 禁止其他节点 root 账户登录- : ALL : 192.168.0. # 禁止内网其他用户登录 Firewall-cmd 防火墙配置通过查看 /var/log/secure 文件，发现有几个ip在大量尝试暴力破解root密码，因此决定增加防火墙防止被攻击 1234567891011# 安装防火墙服务yum install firewalld# 查看防火墙状态firewall-cmd --state# 设置开机自动启动systemctl enable firewalld# 开启防火墙systemctl start firewalld 由于 Torque + MAUI 的配置中，管理节点需要和计算节点进行通信，因此需要开放几个端口 1234567891011firewall-cmd --add-port=15001/tcp --permanentfirewall-cmd --add-port=15002/tcp --permanentfirewall-cmd --add-port=15003/tcp --permanentfirewall-cmd --add-port=42559/tcp --permanentfirewall-cmd --add-port=8080/tcp --permanent# 这样配置比较麻烦，设置直接信任内网网卡firewall-cmd --zone=trusted --change-interface=enp1s0 --permanent# 重启防火墙使得配置生效firewall-cmd --reload 对于之前发现的ip，进行了手动封禁ip 12345# 查看尝试次数比较多的ip列表grep \"Failed password\" /var/log/secure | awk '&#123;print $11&#125;' | sort | uniq -c | sort -n -r -k 1 | head# 手动封禁firewall-cmd --permanent --add-rich-rule=\"rule family='ipv4' source address='120.133.22.121' reject\" 如果需要解封，可以编辑 /etc/firewalld/zones/public.xml 配置文件，删除ip对应的字段 1234&lt;rule family=\"ipv4\"&gt; &lt;source address=\"178.128.149.100\"/&gt; &lt;reject/&gt;&lt;/rule&gt; Fail2ban 自动ban ip手动封禁还是比较麻烦的，因此使用了 Fail2ban 对短时间大量尝试的ip进行自动封禁 123# 安装服务与开机自启yum install fail2bansystemctl enable fail2ban 配置文件位于 /etc/fail2ban/jail.local 1234567891011121314[DEFAULT]ignoreip = 127.0.0.1/8 172.16.0.0/8 127.0.0.1 10.0.0.0/8 192.168.0.0/16 1.2.3.4bantime = 86400findtime = 600maxretry = 10banaction = firewallcmd-ipsetaction = %(action_mwl)s[sshd]enabled = truefilter = sshdport = 22action = %(action_mwl)slogpath = /var/log/secure 这样配置后，可以禁止在10分钟内 ssh 错误超过10次的ip继续尝试登录 12345678# 启动服务systemctl start fail2ban# 查看目前运行状态，可以看到被ban的ipfail2ban-client status sshd# 解封ipfail2ban-client set sshd unbanip 172.16.100.1 其他设置曙光节点重新配置经过测试，这样直接配置可以进行任务投递，但是任务结束时无法获取 Complete 的状态，可能是曙光使用的 Torque 版本号不同所导致，需要对于所有的计算节点重新配置版本号对应的 Torque-client，但是仍然需要关闭Gridview服务的自启 曙光服务位置在 /opt/gridview 通过配置文件 /opt/gridview/pbs/dispatcher/mom_priv/config 可以为曙光节点重新指定 pbs 管理节点 12$pbsserver node71$restricted *.node71 修改成功后，重启 pbs_mom 服务 1service pbs_mom restart 禁用 gridview 相关服务的自启动 123456789# 查看所有自启动服务chkconfig --list# 关闭 gridview_platform 服务自启chkconfig gridview_platform off# 这两项服务是 pbs 需要的，不用关闭chkconfig pbs_mom onchkconfig trqauthd on","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"服务器使用 NFS 挂载移动硬盘","slug":"CentOS_Server_NFS","date":"2019-05-29T06:30:34.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/05/29/CentOS_Server_NFS/","link":"","permalink":"https://kevinzjy.github.io/2019/05/29/CentOS_Server_NFS/","excerpt":"最近在服务器上, 经常需要挂载硬盘进行数据拷贝的工作. 然而由于 home 目录 USB 接口数量有限,每次只能通过将硬盘插入计算节点的方式进行挂载. 因此每次需要使用 qsub 提交交互式任务到计算节点上进行数据拷贝, 十分不方便. 因此打算使用 NFS 的方法, 把计算节点上挂载的数据目录挂载在主节点, 进行数据拷贝的工作.","text":"最近在服务器上, 经常需要挂载硬盘进行数据拷贝的工作. 然而由于 home 目录 USB 接口数量有限,每次只能通过将硬盘插入计算节点的方式进行挂载. 因此每次需要使用 qsub 提交交互式任务到计算节点上进行数据拷贝, 十分不方便. 因此打算使用 NFS 的方法, 把计算节点上挂载的数据目录挂载在主节点, 进行数据拷贝的工作. 由于服务器已经部署了 NFS, 因此不记录 NFS 和 rpcbind 服务的安装和配置过程 启动 NFS 和 rpcbind 服务 (需要先安装 nfs-utils)12/etc/init.d/rpcbind start/etc/init.d/nfs start 在计算节点挂载移动硬盘1mount -t ntfs /dev/sdc1 /media/data 将挂载文件夹加入 NFS 发布目录1234vi /etc/exports/media/data 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash)exportfs -r #使配置生效exportfs -v #查看已生效配置 在主目录上挂载数据文件夹1mount node150:/media/data /media/data 卸载硬盘12345678# On PBS managerumount /media/data# On node150echo &apos;&apos; &gt; /etc/exports # clear NFS exportexportfs -rexportfs -vumount /media/data 参考资料:[1]. https://blog.51cto.com/yejiankang/885484","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"Anaconda 构建本地 channel","slug":"Anaconda_Offline_Mirror","date":"2019-05-21T07:49:53.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/05/21/Anaconda_Offline_Mirror/","link":"","permalink":"https://kevinzjy.github.io/2019/05/21/Anaconda_Offline_Mirror/","excerpt":"根据 Anaconda 软件源上的说明，Anaconda 和 Miniconda 是 Anaconda, Inc. 的商标，任何未经授权的公开镜像都是不允许的。此方法只适用于个人用途,国内的清华镜像也因此已经停止服务 (https://mirrors.tuna.tsinghua.edu.cn/news/close-anaconda-service/) 为了缩短 Anaconda 各种第三方包的安装时间, 最近在服务器上构建了 free / main 两个 channel 的本地镜像, 可以安装大部分常用的模块","text":"根据 Anaconda 软件源上的说明，Anaconda 和 Miniconda 是 Anaconda, Inc. 的商标，任何未经授权的公开镜像都是不允许的。此方法只适用于个人用途,国内的清华镜像也因此已经停止服务 (https://mirrors.tuna.tsinghua.edu.cn/news/close-anaconda-service/) 为了缩短 Anaconda 各种第三方包的安装时间, 最近在服务器上构建了 free / main 两个 channel 的本地镜像, 可以安装大部分常用的模块 安装 Anaconda 和 conda buildconda 的安装就不多说了, 直接安装 miniconda / Anaconda 都可以, 安装成功之后, 还需要 conda build 这个工具用来构建本地索引 1conda install conda-build 下载官方 Channel12wget -r --no-parent https://repo.continuum.io/pkgs/main/linux-64/wget -r --no-parent https://repo.continuum.io/pkgs/free/linux-64/ 下载完后, 目录结构为 123456/opt/repo.continuum.io|-- pkgs| |-- free| | |-- linux-64| |-- main| | |-- linux-64 Conda index 构建索引12conda index /opt/repo.continuum.io/pkgs/freeconda index /opt/repo.continuum.io/pkgs/main 如果在 index 过程中, 出现 conda index error: KeyError, 提示某个包的名字没有找到, 此时删除 /opt/repo.continuum.io/pkgs/main/linux-64/patch_instructions.json 后,重新 conda index 即可 使用本地 Channel 安装1conda install -c file:///opt/repo.continuum.io/pkgs/main --override-channels --offline tensorflow-gpu 即可成功使用本地 channel 安装 tensorflow-gpu 模块, 同时在成功配置过一次之后, 再次安装时可以不指定channel, 也会自动搜索本地目录里的模块内容 使用 .condarc 进行配置我们可以通过配置 ~/.condarc 中加入如下内容，使其覆盖原有的default channel（repo.continuum.io/pkgs/free/linux-64），并默认不再联网进行搜索 默认配置内容: 12345channels: - bioconda - conda-forge - defaults - r 修改为 1234channels: - file:///opt/repo.continuum.io/pkgs/free offline: True 这样就可以强制使用本地源进行包的安装了","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"CentOS 配置网络环境","slug":"CentOS_Network_Config","date":"2019-05-21T07:49:53.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/05/21/CentOS_Network_Config/","link":"","permalink":"https://kevinzjy.github.io/2019/05/21/CentOS_Network_Config/","excerpt":"","text":"在 CentOS 安装过程中,如果选择了 minimal 安装,默认是没有安装 net-tools 的,因此 iwconfig 等命令无法正常使用,配置网络环境十分麻烦,查阅了很多资料,终于发现其实自带了一个命令行的网络管理工具 nmtui 使用 nmtui 配置好网络链接后, 输入 service network start 就可以正常使用网络了,然后再使用 yum install net-tools 安装网络工具之后,常用的命令就都能用了","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"},{"name":"CentOS","slug":"CentOS","permalink":"https://kevinzjy.github.io/tags/CentOS/"}]},{"title":"Anaconda3 环境配置","slug":"190408-bash_conda","date":"2019-04-08T08:02:34.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/04/08/190408-bash_conda/","link":"","permalink":"https://kevinzjy.github.io/2019/04/08/190408-bash_conda/","excerpt":"","text":"背景: 最近院里集群存储出现了一点问题，导致 .bashrc 文件无法打开，因此需要重新配置环境。 在配置环境的过程中，先安装了 anaconda3，然而配置好环境变量之后，发现每次登录服务器需要等待 4-5 秒后才会出现命令行提示符，十分难受。经过检查，发现是在 anaconda 安装时配置的环境变量有点问题，将其更改为手动添加后，登录服务器的过程又变得十分顺畅了。 Anaconda3 提供的配置12345678910111213141516# added by Anaconda3 4.5.12 installer# &gt;&gt;&gt; conda init &gt;&gt;&gt;# !! Contents within this block are managed by 'conda init' !!__conda_setup=\"$(CONDA_REPORT_ERRORS=false '$HOME/software/anaconda3/bin/conda' shell.bash hook 2&gt; /dev/null)\"if [ $? -eq 0 ]; then \\eval \"$__conda_setup\"else if [ -f \"$HOME/software/anaconda3/etc/profile.d/conda.sh\" ]; then . \"$HOME/software/anaconda3/etc/profile.d/conda.sh\" CONDA_CHANGEPS1=false conda activate base else \\export PATH=\"$HOME/software/anaconda3/bin:$PATH\" fifiunset __conda_setup# &lt;&lt;&lt; conda init &lt;&lt;&lt; 手动添加的配置12. $HOME/software/anaconda3/etc/profile.d/conda.shconda activate 更新 经过进一步的检查,发现 virtualenvwrapper 也占用了大量的启动时间,于是也改成了 lazy loading 模式,这样每次输出 workon 命令才会加载相关文件,而不需要在登录时就进行长时间的等待了 12export VIRTUALENVWRAPPER_SCRIPT=/histor/zhao/zhangjy/software/anaconda3/bin/virtualenvwrapper.shsource /histor/zhao/zhangjy/software/anaconda3/bin/virtualenvwrapper_lazy.sh","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"Ubuntu Server 18.04 LTS 安装","slug":"190304-Ubuntu-ServerInstall","date":"2019-03-04T06:22:57.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/03/04/190304-Ubuntu-ServerInstall/","link":"","permalink":"https://kevinzjy.github.io/2019/03/04/190304-Ubuntu-ServerInstall/","excerpt":"实验室使用的 2011-mid 21.5 iMac 实在太卡，于是找老板更换了新电脑，打算装 Ubuntu 18.04 LTS，这样方便以后学习 ML，","text":"实验室使用的 2011-mid 21.5 iMac 实在太卡，于是找老板更换了新电脑，打算装 Ubuntu 18.04 LTS，这样方便以后学习 ML， 为何选择 Ubuntu Server 而不是 Desktop 版本安装 Ubuntu server 的好处：可以使用 LVM 分区，方法分区大小的调整，在 Ubuntu Desktop 版本中，自动安装的 LVM 分区只能使用默认大小，无法自由设置 Ubuntu Server 的安装准备从 Canonical 官网 下载 Ubuntu server 镜像，使用 Rufus 刻录到U盘作为启动盘 系统分区方案主机硬盘配置: i7 8700 / 16G / GTX1060 6G，512G N.vMe SSD + 3T HDD 为了保证系统速度，以及为了不会因为数据问题重新分区，采用了下列的分区方案 MOUNT POINT SIZE TYPE DEVICE TYPE / 443.433G ext4 LVM logical volume (SSD) /boot 1.000G ext4 partition of local disk (SSD) /boot/efi 512.000M fat32 partition of local disk (SSD) /home 2.729T ext4 Spartition of local disk (HDD) SWAP 32.000G swap LVM logical volume (SSD) 在默认的 LVM 分区中，/ 根分区大小只有 4G，在SSD上还剩下400多G的空闲空间，可以分配给想要的分区 ( / 和 swap ) 修改swap分区大小 (适用于Desktop环境)在 Server 版本安装过程中，可以直接设定LVM分区的大小，不需要经过这一步 12345678910sudo swapon --showfree -hdf -lhsudo lvsls /dev/mapperswapoff -a # 关闭swap分区lvreduce -L -31G /dev/mapper/ubuntu--vg-root # 根目录缩减空间lvextend -L +31G /dev/mapper/ubuntu--vg-swap_1 # 将空闲空间分配给swapswapon -a # 重新打开swap 缩减根目录空间可能导致数据丢失，建议还是直接使用 Server 版本进行安装 网络连接配置Ubuntu 18.04 LTS 中，默认使用 netplan 进行网络配置，然而在安装时，先暂时使用 ifconfig 命令配置联网，用来安装后续需要的软件 123456ifconfig -a # 列出网卡ifconfig enp4s0 down # 关闭有线网卡ifconfig enp4s0 hw ether 98:ee:cb:95:c9:0e # 更改硬件地址ifconfig enp4s0 up # 重新打开有线网卡ping www.baidu.com 在系统安装过程中，发现默认的网卡配置连不上网，可能上级路由配置问题，更改硬件 MAC 地址后，会重新分配到新 IP，就可以成功联网了 安装 Grub 引导分区123456789101112fdisk -lmkdir /mntmount /dev/ubuntu-vg/ubuntu-lv /mntmkdir /mnt/boot/efimount /dev/nvme0n1p1 /boot/efifor i in /dev/ /dev/pts /proc /sys; do mount -B $i /mnt$i; doneapt install grub-efi-amd64grub-install --no-nvram --root-directory=/mnt /dev/nvme0n1p1sudo chroot /mntsudo update-grub 进入 Grub 引导模式，配置UEFI启动12345grub rescue &gt; lsls (hd1,gpt2)/set root=(hd1,gpt2)insmod linuxlinux (hd1,gpt2)/vmlinuz-4.15.0-29-generic UEFI启动，开机时按ESC进入grub模式 12345mount -o rw,remount /ls /home/passwd rootreboot 在 grub 模式中挂载好分区，然后更改 root 密码，就可以成功进入系统了 网络配置配置静态ip地址，网关和DNS 123456789101112network: version: 2 renderer: NetworkManager ethernets: enp4s0: addresses: - 10.4.0.140/24 gateway4: 10.4.0.1 nameservers: addresses: [8.8.8.8, 8.8.4.4] search: [] optional: true 随机设置网卡 MAC 地址 1234ifconfig enp4s0 upifconfig enp4s0 10.4.0.246 netmask 255.255.255.0 broadcast 10.4.0.255ip route add default via 10.4.0.1openssl rand -hex 6 | sed &apos;s/\\(..\\)/\\1/g; s/.$//&apos; | xargs ifconfig enp4s0 hw ether 安装无线网卡管理和桌面环境 123apt install xfce4apt install wicdstartx 添加自己的用户123adduser zhangjyvim /etc/sudoers # 在 sudoers 中，为账户配置 root 权限zhangjy ALL=(ALL) ALL","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/tags/Ubuntu/"}]},{"title":"Linux 服务器中异常排查","slug":"190225-Linux-miner","date":"2019-02-25T10:57:47.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/02/25/190225-Linux-miner/","link":"","permalink":"https://kevinzjy.github.io/2019/02/25/190225-Linux-miner/","excerpt":"今天，在登录服务器时，发现非常卡顿，并且计算中心提醒服务器最近占用了大量的下行带宽，因此怀疑服务器上可能存在异常的程序，决定进行一波排查","text":"今天，在登录服务器时，发现非常卡顿，并且计算中心提醒服务器最近占用了大量的下行带宽，因此怀疑服务器上可能存在异常的程序，决定进行一波排查 检查网络流量1iftop 最右侧三列为 2s/4s/10s 内占用平均带宽 通过 top 查看系统 CPU 和内存占用1glances 检查异常进程相关文件12345lsof -p $&#123;pid&#125;ls -al /proc/$&#123;pid&#125;ls -al /proc/$&#123;pid&#125;/fdcat /proc/$&#123;pid&#125;/fd/255 &gt; /tmp/$&#123;pid&#125;.255cat /proc/$&#123;pid&#125;/exe &gt; /tmp/$&#123;pid&#125;.exe 检查计划任务123ls /var/spool/cronls /etc/cron.hourlyless -S /etc/crontab 检查自动启动的服务123service --status-all | grep runningchkconfig --list | grep :onless -S /etc/rc.local 检查自动启动脚本123ls -lt /etc/init.d | headless -S /etc/rc.localls /etc/rc.d 清除文件名异常的文件经过检查，发现在 /tmp 文件夹下存在一个名称为 “. “ 的文件，然而一开始在 CentOS 的 shell 里面只看到了 “.”，因此一直无法删除。最后只好使用文件的 index number 进行操作 123456➜ tmp ls -altotal 2556drwxrwxr-x 2 zhangjy zhangjy 4096 Feb 25 19:13 .-rwxrwxr-x 1 zhangjy zhangjy 1981324 Nov 2 06:36 &apos;. &apos;drwxrwxr-x 3 zhangjy zhangjy 4096 Feb 25 18:59 ..-rwxr-xr-x 1 zhangjy zhangjy 625867 Feb 25 19:13 libudev.so 获取 index number 123456➜ tmp ls -ialtotal 2556118621432 drwxrwxr-x 2 zhangjy zhangjy 4096 Feb 25 19:13 .118621437 -rwxrwxr-x 1 zhangjy zhangjy 1981324 Nov 2 06:36 '. '118621454 drwxrwxr-x 3 zhangjy zhangjy 4096 Feb 25 18:59 ..118621435 -rwxr-xr-x 1 zhangjy zhangjy 625867 Feb 25 19:13 libudev.so 根据 index number 删除文件 1find . -inum 118621437 -exec rm -i &#123;&#125; \\; 总结最终经过排查发现，服务器上存在 https://github.com/xmrig/xmrig 恶意挖矿程序，并且攻击者都明文记录了 mining server ip 以及 USERNAME/PASSWORD，非常嚣张 参考资料: https://blog.51cto.com/qicheng0211/1928738","categories":[{"name":"GitHub","slug":"GitHub","permalink":"https://kevinzjy.github.io/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kevinzjy.github.io/tags/GitHub/"}]},{"title":"RedHat6 升级 GLIBC","slug":"190117-Server-gcc","date":"2019-01-17T13:13:09.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/01/17/190117-Server-gcc/","link":"","permalink":"https://kevinzjy.github.io/2019/01/17/190117-Server-gcc/","excerpt":"在安装 Nanopore 测序平台需要的 Guppy 等软件时，发现集群上系统是 RHEL6.3，自带 gcc 4.4.6和 glibc 2.12，已经远远落后于时代了，新软件编译时经常报错，提示需要 GLIBC 2.17，因此今天着手升级了一下 gcc 和 glibc 的版本","text":"在安装 Nanopore 测序平台需要的 Guppy 等软件时，发现集群上系统是 RHEL6.3，自带 gcc 4.4.6和 glibc 2.12，已经远远落后于时代了，新软件编译时经常报错，提示需要 GLIBC 2.17，因此今天着手升级了一下 gcc 和 glibc 的版本 升级 glibc 2.17查看 RedHat 发行版本 12[root@node5 ~]# cat /etc/redhat-releaseRed Hat Enterprise Linux Server release 6.3 (Santiago) 查看现在 GLIBC 的版本，支持最高只到 2.12 1234567891011121314151617[root@node5 ~]# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE 在安装之前，先在确认内核版本支持 glibc_2.17 glibc 2.17 (25 Dec 2012)Note: the minimum Linux kernel version to run with this and later glibc versions is Linux 2.6.16. API changes include the following: A new secure_getenv() function allows secure access to the environment. It is similar to getenv(3), but returns NULL if running in a set-user-ID/set-group-ID process. Documentation can be found in the secure_getenv(3) manual page.The functions clock_getres(), clock_gettime(), clock_settime(), clock_getcpuclockid(), and clock_nanosleep(), moved from the realtime library (librt to the main C library. Consequently, it is no longer necessary to link against the realtime library (cc -lrt) when using these functions. The rationale for this change is explained in glibc bug 14743 (“clock_gettime et al from -lrt always bring in libpthread”). 可以看到，系统内核版本为 2.6.32，而 glibc_2.17 支持 2.6.16 以上的内核，因此应该可以安装 12[root@node5 ~]# uname -aLinux node5 2.6.32-279.el6.x86_64 #1 SMP Wed Jun 13 18:24:36 EDT 2012 x86_64 x86_64 x86_64 GNU/Linux 查看需要安装的 glibc 相关模块 12345678[root@node5 ~]# rpm -qa | grep glibccompat-glibc-headers-2.5-46.2.x86_64glibc-2.12-1.80.el6.x86_64compat-glibc-2.5-46.2.x86_64glibc-devel-2.12-1.80.el6.x86_64glibc-headers-2.12-1.80.el6.x86_64glibc-2.12-1.80.el6.i686glibc-common-2.12-1.80.el6.x86_64 下载对应的 glibc 2.17 版本安装包，参考 (https://gist.github.com/harv/f86690fcad94f655906ee9e37c85b174)，将需要用到的5个安装包，放在同一文件夹内 x86_64 下载地址 | i386 下载地址 1234567[root@node5 glibc]# lltotal 24767-rw-r--r-- 1 root root 4835780 Feb 17 2015 glibc-2.17-55.el6.i686.rpm-rw-r--r-- 1 root root 4181172 Feb 17 2015 glibc-2.17-55.el6.x86_64.rpm-rw-r--r-- 1 root root 14624176 Feb 17 2015 glibc-common-2.17-55.el6.x86_64.rpm-rw-r--r-- 1 root root 1043692 Feb 17 2015 glibc-devel-2.17-55.el6.x86_64.rpm-rw-r--r-- 1 root root 677944 Feb 17 2015 glibc-headers-2.17-55.el6.x86_64.rpm 同时安装glibc相关的包，如果单独安装会出现依赖问题 12345678910111213[root@node14 glibc]# rpm -Uvh ./*warning: ./glibc-2.17-55.el6.i686.rpm: Header V3 RSA/SHA1 Signature, key ID 73ec361c: NOKEYPreparing... ########################################### [100%] 1:glibc-common ########################################### [ 20%]/usr/sbin/build-locale-archive: /lib64/libc.so.6: version `GLIBC_2.14&apos; not found (required by /usr/sbin/build-locale-archive)/usr/sbin/build-locale-archive: /lib64/libc.so.6: version `GLIBC_2.14&apos; not found (required by /usr/sbin/build-locale-archive) 2:glibc ########################################### [ 40%] 3:glibc-headers ########################################### [ 60%] 4:glibc-devel ########################################### [ 80%] 5:glibc warning: /etc/nsswitch.conf created as /etc/nsswitch.conf.rpmnewwarning: /etc/rpc created as /etc/rpc.rpmnew########################################### [100%]warning: /etc/localtime saved as /etc/localtime.rpmsave 安装完成后，检查是否已经支持 GLIBC_2.17 12345678910111213141516171819202122[root@node5 glibc]# strings /lib64/libc.so.6 | grep GLIBCGLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_PRIVATE 升级成功！ P.S. RPM 升级会导致时区设置清空，重新设置为当前时区后，和管理节点同步时间即可 123[root@node5 ~]# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime[root@node5 ~]# ntpdate node7817 Jan 20:49:05 ntpdate[26445]: adjust time server 192.168.0.78 offset -0.010161 sec 升级 gcc当前 gcc 版本为 4.4.7 12345[root@node5 ~]# gcc --versiongcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)Copyright (C) 2010 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 为了不影响其他依赖的软件包，我们使用 devtoolset-2 单独安装一份 gcc 4.8.2 1[root@node5 ~]# wget -O /etc/yum.repos.d/slc6-devtoolset.repo http://linuxsoft.cern.ch/cern/devtoolset/slc6-devtoolset.repo 在可以联网的节点下载 devtoolset-2 的安装包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@manager ~]# yum install --downloadonly --downloaddir=/histor/software/yum_download devtoolset-2-gcc-c++-4.8.2-15.1.el6Loaded plugins: aliases, changelog, downloadonly, kabi, presto, product-id, security, subscription- : manager, tmprepo, verify, versionlockUpdating certificate-based repositories.Unable to read consumer identityLoading support for Red Hat kernel ABISetting up Install ProcessResolving Dependencies--&gt; Running transaction check---&gt; Package devtoolset-2-gcc-c++.x86_64 0:4.8.2-15.1.el6 will be installed--&gt; Processing Dependency: devtoolset-2-libstdc++-devel = 4.8.2-15.1.el6 for package: devtoolset-2-gcc-c++-4.8.2-15.1.el6.x86_64--&gt; Processing Dependency: devtoolset-2-gcc = 4.8.2-15.1.el6 for package: devtoolset-2-gcc-c++-4.8.2-15.1.el6.x86_64--&gt; Running transaction check---&gt; Package devtoolset-2-gcc.x86_64 0:4.8.2-15.1.el6 will be installed--&gt; Processing Dependency: devtoolset-2-runtime for package: devtoolset-2-gcc-4.8.2-15.1.el6.x86_64---&gt; Package devtoolset-2-libstdc++-devel.x86_64 0:4.8.2-15.1.el6 will be installed--&gt; Running transaction check---&gt; Package devtoolset-2-runtime.noarch 0:2.1-4.el6 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved======================================================================================================== Package Arch Version Repository Size========================================================================================================Installing: devtoolset-2-gcc-c++ x86_64 4.8.2-15.1.el6 slc6-devtoolset 7.2 MInstalling for dependencies: devtoolset-2-gcc x86_64 4.8.2-15.1.el6 slc6-devtoolset 21 M devtoolset-2-libstdc++-devel x86_64 4.8.2-15.1.el6 slc6-devtoolset 1.9 M devtoolset-2-runtime noarch 2.1-4.el6 slc6-devtoolset 1.0 MTransaction Summary========================================================================================================Install 4 Package(s)Total download size: 32 MInstalled size: 71 MIs this ok [y/N]: yDownloading Packages:Setting up and reading Presto delta metadataProcessing delta metadataPackage(s) data still to download: 32 M(1/4): devtoolset-2-gcc-4.8.2-15.1.el6.x86_64.rpm | 21 MB 03:40(2/4): devtoolset-2-gcc-c++-4.8.2-15.1.el6.x86_64.rpm | 7.2 MB 01:37(3/4): devtoolset-2-libstdc++-devel-4.8.2-15.1.el6.x86_64.rpm | 1.9 MB 00:19(4/4): devtoolset-2-runtime-2.1-4.el6.noarch.rpm | 1.0 MB 00:08---------------------------------------------------------------------------------------------------------------------------------------Total 92 kB/s | 32 MB 05:51exiting because --downloadonly specified 切换到计算节点，安装下载的 devtoolset-2 12345678[root@node5 yum_download]# rpm -Uvh ./*.rpmwarning: ./devtoolset-2-gcc-4.8.2-15.1.el6.x86_64.rpm: Header V4 DSA/SHA1 Signature, key ID 1d1e034b: NOKEYPreparing... ########################################### [100%] 1:devtoolset-2-runtime ########################################### [ 25%]libsemanage.get_home_dirs: mails homedir /var/mails or its parent directory conflicts with a file context already specified in the policy. This usually indicates an incorrectly defined system account. If it is a system account please make sure its uid is less than 500 or its login shell is /sbin/nologin. 2:devtoolset-2-gcc ########################################### [ 50%] 3:devtoolset-2-libstdc++-########################################### [ 75%] 4:devtoolset-2-gcc-c++ ########################################### [100%] 启用 devtoolset-2 1[root@node5 ~]# source /opt/rh/devtoolset-2/enable 查看 gcc 版本 12345[root@node5 ~]# gcc --versiongcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 成功！","categories":[{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/categories/Server/"}],"tags":[{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"GitHub撤销已提交的commit","slug":"190116-gitReset","date":"2019-01-16T08:46:06.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/01/16/190116-gitReset/","link":"","permalink":"https://kevinzjy.github.io/2019/01/16/190116-gitReset/","excerpt":"","text":"今天在向 GitHub 提交某个 commit 时，发现不小心将 Key 配置直接写在了配置文件内，为了安全起见，需要撤销这个 commit 12git reset --hard HEAD~1gut push --force 这样即使在GitHub的历史commit里，也看不到上次的改动了","categories":[{"name":"GitHub","slug":"GitHub","permalink":"https://kevinzjy.github.io/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kevinzjy.github.io/tags/GitHub/"}]},{"title":"Linux解决根目录ls无响应问题","slug":"190115-Linux-lsNotResponding","date":"2019-01-15T08:47:15.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/01/15/190115-Linux-lsNotResponding/","link":"","permalink":"https://kevinzjy.github.io/2019/01/15/190115-Linux-lsNotResponding/","excerpt":"","text":"今天发现服务器某节点，在根目录执行ls时会卡死 首先用 which ls 命令查看 ls 命令的alias 12alias ls=&apos;ls --color=auto&apos; /bin/ls 直接执行 /bin/ls 命令可以获得结果，因此需要追踪 strace ls --color=auto / 在哪个目录出现了问题 查看输出结果可以发现，会卡在某个NFS文件夹，umount 之后就可以了 1umount -l /data","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"}]},{"title":"Ubuntu实现Java版本切换","slug":"190115-Ubuntu-javaVersionSwitch","date":"2019-01-15T08:47:15.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2019/01/15/190115-Ubuntu-javaVersionSwitch/","link":"","permalink":"https://kevinzjy.github.io/2019/01/15/190115-Ubuntu-javaVersionSwitch/","excerpt":"","text":"在使用IGV的时候，发现软件提示需要 java8，然而系统上已经同时安装了 java8 和 java11 12sudo apt install openjdk-8-jdksudo apt install openjdk-11-jdk 可以看到 /usr/bin/java 指向的是 java11 的版本，因此我们只需要重新设置成 java8 就好了 1234$ java -versionopenjdk version \"10.0.2\" 2018-07-17OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4)OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode) 将系统默认使用的 java 版本更改为 java8 1234567891011$ sudo update-alternatives --config javaThere are 2 choices for the alternative java (providing /usr/bin/java). Selection Path Priority Status------------------------------------------------------------ 0 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 1081 auto mode 1 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 300 manual mode* 2 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 1081 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 输入对应的编号之后，就可以成功使用需要的 jdk 版本了 1234$ java -versionopenjdk version \"1.8.0_191\"OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-0ubuntu0.18.04.1-b12)OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/tags/Ubuntu/"}]},{"title":"Linux 服务器挂载 NTFS / exFAT 格式硬盘","slug":"181105-Server-NTFS","date":"2018-11-05T12:16:40.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2018/11/05/181105-Server-NTFS/","link":"","permalink":"https://kevinzjy.github.io/2018/11/05/181105-Server-NTFS/","excerpt":"Linux 下默认的硬盘格式为 ext4 / ext3，因此如果想要挂载平时更加常用的 NTFS / exFAT 格式移动硬盘，需要额外安装驱动 安装 NTFS / exFAT 支持需要root权限，服务器请联系管理员解决…","text":"Linux 下默认的硬盘格式为 ext4 / ext3，因此如果想要挂载平时更加常用的 NTFS / exFAT 格式移动硬盘，需要额外安装驱动 安装 NTFS / exFAT 支持需要root权限，服务器请联系管理员解决… 系统环境通过 lsb_release -a 命令查看当前系统版本 123456$ lsb_release -aLSB Version: :core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarchDistributor ID: RedHatEnterpriseServerDescription: Red Hat Enterprise Linux Server release 6.3 (Santiago)Release: 6.3Codename: Santiago 下载驱动程序下载 ntfs-3g, fuse, fuse-exfat 和 exfat-utils 的 RPM 安装包 1234$ wget http://download1.rpmfusion.org/free/el/updates/6/x86_64/exfat-utils-1.3.0-1.el6.x86_64.rpm$ wget http://download1.rpmfusion.org/free/el/updates/6/x86_64/fuse-exfat-1.3.0-1.el6.x86_64.rpm$ wget https://www.rpmfind.net/linux/epel/6/x86_64/Packages/n/ntfs-3g-2017.3.23-6.el6.x86_64.rpm$ wget https://www.rpmfind.net/linux/centos/6.10/os/x86_64/Packages/fuse-2.8.3-5.el6.x86_64.rpm 安装注意安装顺序，先安装 fuse-exfat 再安装 exfat-utils 1234$ rpm -Uvh ntfs-3g-2017.3.23-6.el6.x86_64.rpm$ rpm -Uvh fuse-2.8.3-5.el6.x86_64.rpm$ rpm -Uvh fuse-exfat-1.3.0-1.el6.x86_64.rpm$ rpm -Uvh exfat-utils-1.3.0-1.el6.x86_64.rpm 出现的问题安装过程中如果提示 1/sbin/mount.ntfs-3g: symbol lookup error: /sbin/mount.ntfs-3g: undefined symbol: ntfs_xattr_build_mapping libntfs-3g 动态库版本过低，可以通过 ldd 命令查看 ntfs-3g 依赖的动态库版本 1234567$ ldd /bin/ntfs-3g linux-vdso.so.1 =&gt; (0x00007fffac8eb000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00002ace10591000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00002ace10796000) libntfs-3g.so.88 =&gt; /lib/libntfs-3g.so.88 (0x00002ad751769000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00002ace10c02000) /lib64/ld-linux-x86-64.so.2 (0x00002ace1036e000) 我们刚刚安装的动态库位于 /lib64/libntfs-3g.so.88，而系统调用的仍然是 /lib/libntfs-3g.so.88 的老版本库，因此将 /lib/libntfs-3g.so 更名让程序无法调用即可 12345678910$ cd /lib$ mv libntfs-3g.so.88 libntfs-3g.so.88.unwanted$ ldd $(which ntfs-3g) linux-vdso.so.1 =&gt; (0x00007fffac8eb000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00002ace10591000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00002ace10796000) libntfs-3g.so.88 =&gt; /lib64/libntfs-3g.so.88 (0x00002ace109b3000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00002ace10c02000) /lib64/ld-linux-x86-64.so.2 (0x00002ace1036e000) 可以看到 ntfs-3g 依赖的动态库已经指定为我们新安装的版本 挂载首先通过 fdisk -l 命令确定需要挂载的分区，例如 /dev/sdc2 创建挂载点文件夹1$ mkdir /NAS 将分区挂载到指定的挂载点 12345# NTFS 格式$ mount -t ntfs-3g /dev/sdc2 /NAS# exFAT 格式$ mount.exfat /dev/sdc2 /NAS 卸载硬盘1umount -l /NAS 参考链接：[1]. http://docs.gz.ro/node/162","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"PBS作业管理系统使用技巧","slug":"180813-Server-PBS","date":"2018-08-13T06:16:14.000Z","updated":"2020-12-26T08:24:26.693Z","comments":true,"path":"2018/08/13/180813-Server-PBS/","link":"","permalink":"https://kevinzjy.github.io/2018/08/13/180813-Server-PBS/","excerpt":"PBS是一种十分常用的集群作业调度系统，主要包括openPBS, PBS Pro和Torque三种分支。本文以Torque为例，简单介绍一下PBS作业调度系统的使用技巧 Torque介绍什么是TORQUE： Terascale Open-source Resource and QUEue Manager (TORQUE) 是一个分布式计算节点和批处理作业的资源调度系统，常在高性能计算集群中用于计算作业的提交和管理。用户可以使用TORQUE将计算作业提交到不同计算队列，常用的命令包括qsub(提交作业), qstat(作业状态查询)和qdel(删除作业) 官网地址： http://www.adaptivecomputing.com/support/documentation-index/torque-resource-manager-documentation/","text":"PBS是一种十分常用的集群作业调度系统，主要包括openPBS, PBS Pro和Torque三种分支。本文以Torque为例，简单介绍一下PBS作业调度系统的使用技巧 Torque介绍什么是TORQUE： Terascale Open-source Resource and QUEue Manager (TORQUE) 是一个分布式计算节点和批处理作业的资源调度系统，常在高性能计算集群中用于计算作业的提交和管理。用户可以使用TORQUE将计算作业提交到不同计算队列，常用的命令包括qsub(提交作业), qstat(作业状态查询)和qdel(删除作业) 官网地址： http://www.adaptivecomputing.com/support/documentation-index/torque-resource-manager-documentation/ Torque使用基础作业提交和管理命令 命令 功能 使用说明 示例 qsub 提交pbs作业 qsub [script] $ qsub job.pbs qdel 删除pbs作业 qdel [job_id] $ qdel 12345 qhold 挂起pbs作业 qhold [job_id] $ qhold 12345 qrls 释放挂起的pbs作业 qrls [job_id] $ qrls 12345 作业状态查询命令 命令 说明 qstat -q 列出所有队列 qstat -a 列出所有作业 qstat -u user_id 列出user_id的所有作业 qstat -r 列出所有正在运行的作业 qstat -f job_id 列出作业job_id的信息 qstat -fQ queue 列出队列queue的信息 qstat -B 列出所有作业状态的汇总 pbsnodes 列出所有节点的详细信息 pestat 列出所有节点的状态 PBS作业参数12345678#!/bin/bash#PBS -l nodes=1:ppn=16#PBS -l walltime=1000:00:00#PBS -q high#PBS -N Job_Name#PBS -oeyour_commands_goes_here 提交交互式作业我们可以通过-I选项提交一个交互式的作业，效果类似直接ssh登录到计算节点 qsub -I -N stdin -l nodes=1:ppn=16 -l walltime=1000:00:00 -q high 批量提交作业在很多情况下，我们需要提交大量相似的任务，比如大量样本的转录组数据分析，每个样本数据的分析流程都是一致的，提交的脚本中一般只有样本名字不同，那么如果对每个样本产生产生一个shell脚本，是非常麻烦的。在这种情况下，我们可以通过任务模板与qsub -v命令，进行作业提交时的参数传递。 模板任务文件：template.sh 1234567#!/bin/bash#PBS -j oe#PBS -q high#PBS -l nodes=1:node:ppn=4#PBS walltime=1000:00:00hisat2 -p 4 -x hg19 -1 ./reads/$&#123;sample&#125;_1.fq.gz -2 ./reads/$&#123;sample&#125;_2.fq.fz -t | samtools view -bS &gt; ./align/$&#123;sample&#125;.bam 任务参数文件：job_params.csv123sample1sample2sample3 任务投递脚本：qsub.py1234567891011121314151617181920#!/usr/bin/env pythonimport csvimport subprocessimport timeparam_file = './job_params.csv'cwd = '/home/kevinzjy/RNA-seq'with open(param_file, 'r') as f: reader = csv.reader(f) for sample in reader: qsub_cmd = 'qsub -N &#123;0&#125; -d &#123;1&#125; -v SAMPLE=&#123;0&#125; template.sh'.format(sample, cwd) # print qsub_cwd exit_status = subprocess.call(qsub_cmd, shell=True) if exit_status is 1: print 'Job \"&#123;&#125;\" failed to submit'.format(qsub_cwd) time.sleep(1)print \"Done submitting jobs!\" 通过qsub.py，我们可以实现对job_params.csv里面每一行对应的样本数据 批量删除作业如果要删除一个用户所有的作业，可以使用qselect结合xargs命令，进行作业编号的提取和对指定编号作业的删除 qselect -u user_id | xargs qdel 利用qselect命令，我们可以增加参数进一步缩减选择的作业范围，详细信息可以参考man qselect中的说明 参数 说明 -N 指定作业名字 -s 指定状态 [EHQRTW] -u 指定用户列表 删除某用户所有正在排队的任务： 1qselect -u user_name -s Q | xargs qdel xargs命令的作用是读入标准输入的内容并分行，对其中每一行的内容都执行相同的命令，在这里xargs读入了前面管道中qselect命令得到的某用户的所有作业编号，对于每个编号执行了qdel命令，起到了删除该用户名下所有作业的效果","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Bioinfomatics","slug":"Bioinfomatics","permalink":"https://kevinzjy.github.io/tags/Bioinfomatics/"}]},{"title":"ggplot2作图技巧","slug":"180808-R-ggplot","date":"2018-08-08T15:04:04.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2018/08/08/180808-R-ggplot/","link":"","permalink":"https://kevinzjy.github.io/2018/08/08/180808-R-ggplot/","excerpt":"patchwork实现ggplot多图拼接patchwork介绍ggplot2是大家使用R语言作图时常用的一个模块，而patchwork可以将多个ggplot图片通过简洁的语法进行拼接，类似功能的模块还有gridExtra::grid.arrange和cowplot::plot_grid，不过个人认为patchwork更好用一些，因为其语法更加贴近普通用户的使用习惯 Github项目地址: https://github.com/thomasp85/patchwork 详细使用说明可以查看项目中README.md","text":"patchwork实现ggplot多图拼接patchwork介绍ggplot2是大家使用R语言作图时常用的一个模块，而patchwork可以将多个ggplot图片通过简洁的语法进行拼接，类似功能的模块还有gridExtra::grid.arrange和cowplot::plot_grid，不过个人认为patchwork更好用一些，因为其语法更加贴近普通用户的使用习惯 Github项目地址: https://github.com/thomasp85/patchwork 详细使用说明可以查看项目中README.md Patchwork的安装1 - 下载并安装Rtools 首先，我们需要下载 Rtools ，一个windows系统下用来编译R模块的程序 rtools下载地址：https://cran.r-project.org/bin/windows/Rtools/ 下载并安装与系统R版本对应的exe文件即可（程序安装包较大，100MB+） 2 - 安装devtools devtools 是用来帮助我们安装第三方开发的R模块的R package 项目地址: https://cran.r-project.org/web/packages/devtools/index.html 可以直接使用 install.packages() 安装 1install.packages(\"devtools\") 3 - 升级rlang版本（非必须） 如果rlang版本较低，在安装 patchwork 时会出现以下报错 12345* installing *source* package &apos;patchwork&apos; ...** R** preparing package for lazy loadingError : object &apos;enexprs&apos; is not exported by &apos;namespace:rlang&apos;ERROR: lazy loading failed for package &apos;patchwork&apos; 升级rlang版本即可解决： 1devtools::install_github(\"r-lib/rlang\", build_vignettes = TRUE) 4 - 安装Patchwork 1devtools::install_github(\"thomasp85/patchwork\") 不要觉得安装过程过于麻烦，当你用上Patchwork的时候就会发现一切都是值得的… 使用diamonds测试数据集绘图以diamonds数据集为例，我们可以简单地绘制两个figure 123456789101112131415library(\"ggplot2\")data(diamonds)p1 &lt;- ggplot(subset(diamonds, carat &gt;= 2.2), aes(x = table, y = price, colour = cut)) + geom_point(alpha = 0.7) + geom_smooth(method = \"loess\", alpha = 0.05, size = 1, span = 1) + theme_bw() + theme(aspect.ratio = 1)p2 &lt;- ggplot(subset(diamonds, carat &gt; 2.2 &amp; depth &gt; 55 &amp; depth &lt; 70), aes(x = depth, fill = cut)) + geom_histogram(colour = \"black\", binwidth = 1, position = \"dodge\") + theme_bw() + theme(aspect.ratio = 1) 我们可以看到，利用默认格式生成的图片配色是非常难看的… Tips: 利用ggsci进行颜色图片美化ggsci总结了许多杂志常用的颜色，内置了多个调色板，该模块可以直接通过CRAN安装 1install.packages(\"ggsci\") 使用ggsci中nejm配色作为自动填充后 12345library(ggsci)p1_npg &lt;- p1 + scale_color_npg()p2_npg &lt;- p2 + scale_fill_npg() 可以看出，利用ggsci绘制出的图片色调明显更加协调了 ggsci提供了多个调色板，可以使用scales包中show_col函数直接查看 1234mypal &lt;- pal_npg(\"nrc\", alpha=0.7)(9)library(scales)show_col(mypal) 利用patchwork合并图片在实际作图中，我们经常会遇到需要合并图片的需求，这时候之前安装的patchwork就派上用场了 123library(patchwork)p &lt;- p1_npg + p2_npg 我们可以看到使用patchwork包后，一条命令就实现了p1和p2的拼接 Tips: 使用自定义函数提取图例对于p1和p2,我们可以提取其中的图例并进行单独排版 12345678get_legend &lt;- function(p) &#123; tmp &lt;- ggplot_gtable(ggplot_build(p)) leg &lt;- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\") legend &lt;- tmp$grobs[[leg]] return(legend)&#125;p1_legend &lt;- get_legend(p1_npg) 在提取出图例之后，可以使用plot_layout指定布局列数和每个子图的宽度 123p_merged &lt;- p1_npg + guides(color=FALSE) + p2_npg + guides(fill=FALSE) + p1_legend + plot_layout(ncol=3, widths = c(3,3,1)) 可以将p1,p2以及图例完美地拼接在一起 Tips: ggplot保存文件ggplot2 中，将 plot 存为 eps 格式可以更加方便地使用 AI 进行后续的编辑和修图 1ggsave(\"./plot.eps\", p_merged) 但是默认的 eps 输出格式不能保存透明度，当图片使用了不同的透明度时，会出现报错 123Warning message:In grid.Call.graphics(L_rect, x$x, x$y, x$width, x$height, resolveHJust(x$just, : 此装置不支持半透明：每一页将被报告一次 此时可以使用 ggsave 中指定 device=cairo_ps,使用 cairo_ps 类型保存图片 1ggsave(\"./plot.eps\", p_merged, device=cairo_ps) 同样，对于使用pdf格式保存的图片，当出现格式问题时，也可以使用cairo_pdf作为保存设备 1ggsave('./plot.pdf', p, device=cairo_pdf)","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Bioinfomatics","slug":"Bioinfomatics","permalink":"https://kevinzjy.github.io/tags/Bioinfomatics/"},{"name":"R","slug":"R","permalink":"https://kevinzjy.github.io/tags/R/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://kevinzjy.github.io/tags/ggplot2/"}]},{"title":"pysam处理bam文件心得","slug":"180727-Python-pysam","date":"2018-07-27T03:13:50.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2018/07/27/180727-Python-pysam/","link":"","permalink":"https://kevinzjy.github.io/2018/07/27/180727-Python-pysam/","excerpt":"pysam以及Samtools使用心得pysam简介pysam 是一个基于 htslib 的 C++ API 进行封装的 python 模块,实现了对 SAM / BAM / CRAM 文件的便捷操作,可以简化 bam 文件处理的代码复杂度，同时也可以处理 VCF / BCF 等其他文件 pysam 的安装pysam 已经在 pypi 中包含，可以直接使用 pip 命令安装 1pip install pysam","text":"pysam以及Samtools使用心得pysam简介pysam 是一个基于 htslib 的 C++ API 进行封装的 python 模块,实现了对 SAM / BAM / CRAM 文件的便捷操作,可以简化 bam 文件处理的代码复杂度，同时也可以处理 VCF / BCF 等其他文件 pysam 的安装pysam 已经在 pypi 中包含，可以直接使用 pip 命令安装 1pip install pysam pysam 的使用统计 bam 文件中总 reads 数目以及比对到参考基因组上的 reads 数目利用 pysam.AlignmentFile 对象，我们可以使用 pysam.AlignmentFile.count() 方法快速统计其中的比对片段数目，然而由于存在一条 read 比对到基因组中多个位置的情况，因此直接统计的比对片段数目与 reads 数是不同的 可以使用 read_callback 参数，使用callback函数对比对片段进行筛选，具体细节请参考pysam API read_callback (string or function) – select a call-back to ignore reads when counting. It can be either a string with the following values: all - skip reads in which any of the following flags are set: BAM_FUNMAP, BAM_FSECONDARY, BAM_FQCFAIL, BAM_FDUP nofilter - uses every single read 使用read_callback结合自定义callback函数，我们可以方便地统计总 reads 数目以及比对到基因组上的reads数 Note: 默认情况下，pysam.AlignmentFile.count() 只统计比对上的片段，因此统计 total reads 数目时需要指定 until_eof=True 参数，才可以包含未比对上的片段信息 下面是一个使用 pysam 统计 total reads 与 mapped reads 数目的实例程序： 1234567891011121314151617181920212223import pysamdef main(bam_file): sam = pysam.AlignmentFile(bam_file, 'rb') total = sam.count(read_callback=total_callback, until_eof=True) unmapped = sam.count(read_callback=unmapped_callback) mapped = total - unmapped return total, mappeddef unmapped_callback(read): \"\"\" callback function for mapped reads \"\"\" return read.is_unmapped or read.mate_is_unmapped and not read.is_supplementary and not read.is_secondarydef total_callback(read): \"\"\" callback function for total reads \"\"\" return not read.is_supplementary and not read.is_secondary pysam 多进程处理 bam 文件pysam中多进程处理需要注意一些事情 - 如何多进程处理bam文件通过pysam.AlignmentFile.fetch()方法，可以提取出比对到指定染色体或者指定区域的比对片段，因此可以多进程同时处理多个染色体上的比对结果 - 注意事项 利用同一个pysam.AlignmentFile句柄同时进行fetch操作可能发生冲突，因此每个进程需要重新打开自己的新句柄，并使用fetch(multiple_iterators=True)参数，使得句柄之间相互独立，可以避免文件读取时发生问题 pysam.AlignedSegment对象不能pickle化，因此无法在多进程中作为其他函数的参数，需要自己构建tuple/list用于参数传递 如果每个子进程都需要相同的辅助数据，可以使用initializer进行全局对象的共享，效率比为每个进程提供相同参数要高很多 实例程序： 123456789101112131415161718192021222324252627282930313233343536373839404142import pysamfrom multiprocess import PoolAUX_DATA=Nonedef initializer(aux_data): global AUX_DATA AUX_DATA=aux_datadef worker(bam_file, chrom): sam = pysam.AlignmentFile(bam_file, 'rb') cnt = 0 for read in sam.fetch(chrom, multiple_iterators=True): # use tuple to process AlignedSegment proc(read_query_name, read_is_mapped) cnt += 1 # use aux_data print AUX_DATA return cntdef proc(query_name, is_mapped): pass:def main(bam_file): sam = pysam.AlignmentFile(bam_file, 'rb') header = sam.header['SQ'] sam.close() aux_data = ['chr1', ;'chr2', 'chr3', ] pool = Pool(thread, initializer, (aux_data, )) jobs = [] for chrom in header: jobs.append(pool.apply_async(worker, (bam_file, chrom, ))) pool.close() pool.join() for job in jobs: ret = job.get() pysam与samtools结合使用在pysam.AlignmentFile()打开bam文件时，一般需要bam文件已经排序并且已建立好index 可以使用sort --threads以及index -@多进程12samtools sort --threads 10 -o test.sorted.bam test.bamsamtools index -@ 10 test.sorted.bam 需要注意，samtools index多进程运行之后生成的index文件的时间戳会出现异常，在程序里需要等待几秒后再使用pysam继续处理，否则会提示index file is older than data 1234import timeimport subprocesssubprocess.call('samtools index -@ 10 test.sorted.bam', shell=True)sam = pysam.AlignmentFile('test.sorted.bam')","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Bioinfomatics","slug":"Bioinfomatics","permalink":"https://kevinzjy.github.io/tags/Bioinfomatics/"},{"name":"python","slug":"python","permalink":"https://kevinzjy.github.io/tags/python/"},{"name":"pysam","slug":"pysam","permalink":"https://kevinzjy.github.io/tags/pysam/"}]},{"title":"Ubuntu VPS上搭建Shadowsocks IPV6代理","slug":"171105-VPS-shadowsocks","date":"2017-11-05T08:31:42.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/11/05/171105-VPS-shadowsocks/","link":"","permalink":"https://kevinzjy.github.io/2017/11/05/171105-VPS-shadowsocks/","excerpt":"最近把DigitalOcean上的VPS的ssh服务搞挂了。。。重新配置了一个Droplet，记录一下配置过程 更新: DigitalOcean因为下载盗版电影被封了。。。现在换了一个Vultr的 更新: Vultr VPS的IP被封了。。。国内电信IPV4环境下无法登陆，更换到阿里云美国节点ECS","text":"最近把DigitalOcean上的VPS的ssh服务搞挂了。。。重新配置了一个Droplet，记录一下配置过程 更新: DigitalOcean因为下载盗版电影被封了。。。现在换了一个Vultr的 更新: Vultr VPS的IP被封了。。。国内电信IPV4环境下无法登陆，更换到阿里云美国节点ECS VPS的系统配置 系统：Ubuntu 16.04 LTS 内存: 1024 MB Memory 硬盘: 25 GB SSD 流量：1000 GB 费用: $5 / 月 Step1: 建立Server在DigitalOcean上面新建一个Droplet在Vultr中新建需要的server，这里选择的是日本的机房 Step2: 登录VPS进行配置修改Root密码 12ssh root@vps_ip # 登录VPSsudo passwd root #修改ROOT密码 Enter new UNIX password: # 输入新密码 Retype new UNIX password: # 再次输入 passwd: password updated successfully 修改时区 1dpkg-reconfigure tzdata #修改时区，选择Asia/Shanghai Current default time zone: ‘Asia/Shanghai’ Local time is now: Fri May 19 15:19:57 CST 2017. Universal Time is now: Fri May 19 07:19:57 UTC 2017. 更新APT源 12apt update # 更新apt源apt upgrade # 升级 推荐新建一个具有Root权限的用户，方便VPS的管理和操作 1234sudo adduser zhangjy # 新建用户# 在 /etc/sudoers 中添加root权限# User privilege specificationzhangjy ALL=(ALL) ALL 下面的操作可以退出后使用新建的账户进行操作 Step3: 安装Shadowsocks服务DigitalOcean上的VPS最大的作用就是可以同时连接ipv4和ipv6服务，在搭建Shadowsocks服务后，可以在校园网下用IPV6代理实现直接访问IPV4网址，不需要登录网关，同时避开了流量计费系统。 1234567sudo apt intall python-pipsudo pip install --upgrade pipsudo pip install setuptools#sudo pip install shadowsockssudo apt install libsodium-devpip install https://github.com/shadowsocks/shadowsocks/archive/master.zip -U 更新: 使用github上最新版本的shadowsocks，可以支持chacha20-ietf-poly1305加密方式，更加稳定 编辑vim /etc/shadowsocks.json，添加如下内容 12345678&#123; \"server\": \"::\", # 监听IPV6地址 \"server_port\": 443, # 使用443端口，更加“安全” \"local_port\": 1080, \"password\": \"PASSWORD\", # 密码 \"timeout\": 600, \"method\": \"aes-256-cfb\"&#125; 在 openssl 版本更新后，需要修改一下 shadowsocks 的源代码 编辑 shadowsocks 中调用 openssl 的脚本1sudo vi /usr/local/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py 将 EVP_CIPHER_CTX_cleanup 替换为 EVP_CIPHER_CTX_reset 1234567852c52&lt; libcrypto.EVP_CIPHER_CTX_reset.argtypes = (c_void_p,)---&gt; libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,)111c111&lt; libcrypto.EVP_CIPHER_CTX_reset(self._ctx)---&gt; libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx) 现在，可以手动开启shadowsocks服务了 1ssserver -c /etc/shadowsocks.json -d restart Step4: 配置shadowsocks服务开机自动启动创建脚本 /etc/init.d/shadowsocks 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/sh### BEGIN INIT INFO# Provides: shadowsocks# Required-Start: $remote_fs $syslog# Required-Stop: $remote_fs $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: start shadowsocks# Description: start shadowsocks### END INIT INFOssstart()&#123; /usr/local/bin/ssserver -c /etc/shadowsocks.json -d start&#125;ssstop()&#123; /usr/local/bin/ssserver-d stop&#125;ssreload()&#123; /usr/local/bin/ssserver -c /etc/shadowsocks.json -d restart&#125;case \"$1\" instart) ssstart ;;stop) ssstop ;;reload) ssreload ;;*) echo \"Usage: $0 &#123;start|reload|stop&#125;\" exit 1 ;;esac 增加文件的执行权限，并加入rc.d中，实现开机启动 12sudo chmod +x /etc/init.d/shadowsockssudo update-rc.d shadowsocks defaults 手动开启shadowsocks服务 1sudo service shadowsocks start Step5: shadowsocks自动重连创建autostart.sh 1234567#!/bin/bashpids=\"$($_CMD pgrep ssserver)\"if [ ! $pids ]; then /usr/local/bin/ssserver -c /etc/shadowsocks.json -d start &gt;&gt; /root/ss.log newid=\"$($_CMD pgrep ssserver)\" echo \"Shadowsocks restarted at pid: $newid\" &gt;&gt; /root/ss.logfi 在crontab配置中，配置每天凌晨重启，以及每分钟检测断线重连 12345crontab -e# 选择[3]: vim.basic# 最后加入0 4 * * * ssserver -c /etc/shadowsocks.json -d restart &gt;&gt; /root/ss.log*/1 * * * * /root/autostart.sh 重启Crontab，使定时任务生效 1service cron reload 其他的配置安装常用的oh-my-zsh, htop, glances等软件，参考Ubuntu软件推荐","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/tags/Ubuntu/"},{"name":"VPS","slug":"VPS","permalink":"https://kevinzjy.github.io/tags/VPS/"}]},{"title":"服务器上软件安装和配置","slug":"171115-VPS-deploy","date":"2017-08-21T07:44:15.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/08/21/171115-VPS-deploy/","link":"","permalink":"https://kevinzjy.github.io/2017/08/21/171115-VPS-deploy/","excerpt":"最近实验室服务器经常出现问题，忍不了了，于是更换了Home目录位置，许多软件和环境配置都不好使了，一怒之下，我决定重装。。。","text":"最近实验室服务器经常出现问题，忍不了了，于是更换了Home目录位置，许多软件和环境配置都不好使了，一怒之下，我决定重装。。。 服务器环境配置Bash 环境配置项目主页 1234567git clone --depth=1 https://github.com/Bash-it/bash-it.git /histor/zhao/zhangjy/software/bash_itcd /histor/zhao/zhangjy/software/bash_it./install.sh# 修改.bashrc 中的themeexport BASH_IT_THEME='clean'PS1=\"$&#123;no_color&#125;\\u$&#123;reset_color&#125;@$&#123;purple&#125;\\h$&#123;reset_color&#125;:$&#123;blue&#125;\\W/$&#123;reset_color&#125; \\[\\$(scm_prompt_info)\\]$ \" 常用开发软件安装使用Anaconda安装Python1234wget https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.shbash Anaconda2-4.4.0-Linux-x86_64.sh# 按空格翻页，输入yes同意terms# 输入一个anaconda2安装位置，必须是未创建的目录 /histor/zhao/zhangjy/software/anaconda2 常用的python模块: Name Description pip (for python 2.7) python-pip pip (for python 3) python3-pip Perl1wget http://www.cpan.org/src/5.0/perl-5.26.0.tar.gz TmuxTmux的安装比较简单，先安装libevent, ncurses 然后安装Tmux 1CFLAGS=&quot;-I/usr/local/libevent/include -I/usr/local/ncurses/include&quot; LDFLAGS=&quot;-L/usr/local/libevent/lib -L/usr/local/ncurses/lib&quot; ./configure --prefix=/usr/local/tmux 环境变量配置 123456789export LD_LIBRARY_PATH=\"/histor/zhao/zhangjy/software/libevent/lib\":$LD_LIBRARY_PATHexport PATH=\"/histor/zhao/zhangjy/software/tmux/bin\":$PATHalias tmux='tmux -2'alias ta='tmux attach -t'alias tad='tmux attach -d -t'alias ts='tmux new-session -s'alias tl='tmux list-sessions'alias tksv='tmux kill-server'alias tkss='tmux kill-session -t' 将下列内容存为~/.tmux.conf 1234567891011121314151617set -g default-terminal &quot;screen-256color&quot;set -g prefix C-xunbind C-bbind r source-file ~/.tmux.conf \\; display &quot;Reloaded&quot;# select panebind k selectp -U # above (prefix k)bind j selectp -D # below (prefix j)bind h selectp -L # left (prefix h)bind l selectp -R # right (prefix l)# resize panebind -r ^k resizep -U 10 # upward (prefix Ctrl+k)bind -r ^j resizep -D 10 # downward (prefix Ctrl+j)bind -r ^h resizep -L 10 # to the left (prefix Ctrl+h)bind -r ^l resizep -R 10 # to the right (prefix Ctrl+l)","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"无重复的RNA-Seq数据进行基因差异表达分析","slug":"170520-Paper-GFOLD","date":"2017-05-20T15:08:22.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/20/170520-Paper-GFOLD/","link":"","permalink":"https://kevinzjy.github.io/2017/05/20/170520-Paper-GFOLD/","excerpt":"GFOLD: a generalized fold change for ranking differentially expressed genes from RNA-Seq data简单介绍一下无重复的RNA-Seq数据如何进行较为准确的差异表达分析 参考资料: Feng J, Meyer CA, Wang Q, Liu JS, Liu XS, Zhang Y. GFOLD: a generalized fold change for ranking differentially expressed genes from RNA-seq data. Bioinformatics 2012 全文链接","text":"GFOLD: a generalized fold change for ranking differentially expressed genes from RNA-Seq data简单介绍一下无重复的RNA-Seq数据如何进行较为准确的差异表达分析 参考资料: Feng J, Meyer CA, Wang Q, Liu JS, Liu XS, Zhang Y. GFOLD: a generalized fold change for ranking differentially expressed genes from RNA-seq data. Bioinformatics 2012 全文链接 AbstractMotivation RNA-Seq目前在转录组分析中，被广泛用来评价基因表达的水平 虽然测序成本在快速降低，但是目前70%的人类RNA-Seq样本仍然没有生物学重复(此文发表在2012年) 目前并没有令人满意的对没有生物学重复的数据进行差异表达分析的方法 Results 文章中提出了GFOLD(Generalized fold change)算法，用来提出具有生物学意义的差异表达排序方法 GFOLD基于变化倍数的对数的后验分布，提出了一个可靠地统计量 GFOLD的方法克服了P-value和Fold change方法的缺陷，提出了更稳定和具有生物学意义的单样本基因差异表达排序的方法 Availability:Bitbucket, 项目主页 Methods:在忽略RNA-seq中的Techinical variance的情况下，一个基因中的Reads数目可以使用泊松分布进行估计, 在一个基因中观测到k条Reads的概率可以表示为:$$P(k)=\\frac{\\lambda^ke^{-\\lambda}}{k!},\\lambda=n\\times l\\times x$$ 其中\\(x\\)是基因的表达量(e.g. RPKM)，\\(n\\)是一个反应样本测序深度的标准化常数,\\(l\\)是基因的长度 根据贝叶斯理论，\\(\\lambda\\)和\\(x\\)为随机变量，因此，\\(\\lambda\\)的后验概率可以表示为:$$Post(\\lambda)\\propto\\frac{\\lambda^ke^{-\\lambda}}{k!}$$ 是一个shape为\\(k+1\\)，scale为\\(1\\)的伽马分布，这里使用均匀分布作为\\(\\lambda\\)的先验分布 根据这个分布，可以计算出表达量变化倍数的对数\\(log_2(x_2/x_1)\\)的后验分布。在计算过程中，涉及到\\(l\\)的计算，可以通过令\\(y_i=l\\times x_i,i\\in\\{1,2\\}\\)，计算(z=log_2(y_2/y_1)\\)来避开。可以明显看出\\(log_2(y_2/y_1)\\)和\\(log_2(x_2/x_1)\\)拥有相同的分布。 为了充分利用到Fold change的后验分布的方差的信息，我们定义Generalized fold change(GFOLD)为:$$ GFOLD(c)=\\left\\{\\begin{aligned}max(t,0)|P_Z(z\\leq t)=c, if\\ mean(Z)\\geq 0 \\\\min(t,0)|P_Z(z\\geq t)=c, if\\ mean(Z)&lt;0\\end{aligned}\\right.$$ 其中\\(P_z\\)是\\(z=log_2(y_2/y_1)\\)的后验分布，\\(c\\)是一个自己定义的参数，默认值为0.01。如果该基因表达上调，则\\(mean(Z)\\geq 0\\)，log2 fold change大于t的概率是\\(1-c\\)。那么，在默认的c下\\(t&lt; mean(Z)\\)，\\(GFOLD(c)\\)计算时根据\\(max(t,0)\\)，将取值为负值的t变成0。 如果\\(GFOLD(c)\\)为0，说明该基因的表达量没有明显变化。而且mean(Z)0时是对称的，因此可以通过\\(GFOLD(c)\\)来为基因的表达量变化进行降序排名，排名靠前的基因有明显的表达上调，而排名末尾的基因为表达量明显下调。 Results 图中展示了，GFOLD和直接计算Log2 fold change以及使用Poisson test获得的p值的比较。可以看出，使用GFOLD进行差异表达打分的排名，同时考虑到了log2 fold change后验分布的均值和方差，排名更具有生物学意义。 GFOLD的实现方法在N足够大的时候，可以发现,log2 fold change的后验概率可以近似于正态分布。根据gamma分布的性质: If \\(X\\sim Gamma(\\alpha, \\theta)\\) and \\(Y\\sim Gamma(\\beta, \\theta)\\) are independently distributed, then \\(X/(X+Y)\\) has a beta distribution with parameters \\(\\alpha\\) and \\(\\beta\\). 可以计算出GFOLD的精确值，但是计算闭合形式的方程过于浪费时间，我们可以使用sampling方法进行粗略的估算。文章中，首先基于Gamma分布对于\\(y_1\\), \\(y_2\\)进行了随机抽样，进而获得\\(z\\)的分布，最终可以算出GFold(c)的值，虽然在小数点精度不是很高，但是与传统的P-value和直接计算Fold change的方法相比，GFOLD的排名应该仍然更可信。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/tags/Bioinformatics/"},{"name":"RNA-Seq","slug":"RNA-Seq","permalink":"https://kevinzjy.github.io/tags/RNA-Seq/"},{"name":"Differential Expression","slug":"Differential-Expression","permalink":"https://kevinzjy.github.io/tags/Differential-Expression/"}]},{"title":"Ubuntu 16.04 LTS 安装搜狗拼音输入法","slug":"170514-Ubuntu-Sogou","date":"2017-05-14T12:00:10.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/14/170514-Ubuntu-Sogou/","link":"","permalink":"https://kevinzjy.github.io/2017/05/14/170514-Ubuntu-Sogou/","excerpt":"记录一下Ubuntu 16.04 LTS中如何安装搜狗拼音输入法 参考: 如何在Sublime Text 3中输入中文 点滴记录——在Ubuntu 14.04中使SublimeText 3支持中文输入法","text":"记录一下Ubuntu 16.04 LTS中如何安装搜狗拼音输入法 参考: 如何在Sublime Text 3中输入中文 点滴记录——在Ubuntu 14.04中使SublimeText 3支持中文输入法 下载安装Sougou输入法在搜狗输入法官方页面，下载适合系统的deb安装文件，安装 1234sudo dpkg -i sogoupinyin_2.1.0.0086_amd64.deb# 如果出现依赖未安装sudo apt install -fsudo dpkg -i sogoupinyin_2.1.0.0086_amd64.deb 设置Fcitx输入法在Ubuntu中，打开System Settings -&gt; Language Support，根据提示安装完整的语言支持，并将Keyboard input method system设为fcitx 在Fcitx中添加搜狗输入法打开Terminal(快捷键 Ctrl + Alt + T)，输入fcitx-configtool，点击添加，去掉勾选的Only Show Current Language，添加Sougou Pinyin 在System Settings -&gt; Keyboard -&gt; Shortcuts -&gt; Typing中，将Switch to next source和Switch to previous source的选项，都设为Diabled(点击选项后，按Backspace)。这样可以禁用系统的切换输入法快捷键，搜狗拼音输入法的默认快捷键为Ctrl + , 在Sublime Text 3中添加搜狗输入法的支持Sublime Text是一款跨平台下十分好用的文本编辑软件，然而在Ubuntu下，默认安装的Sublime Text 3不支持搜狗中文输入法，需要手动编译一个共享库 安装依赖软件安装编译共享库的依赖’build-essential’和’libgtk2.0-dev’ 1sudo apt install build-essential libgtk2.0-dev 编写sublime-imfix.c文件在随意文件添加一个sublime-imfix.c，内容为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/* * sublime-imfix.c * Use LD_PRELOAD to interpose some function to fix sublime input method support for linux. * By Cjacker Huang &lt;jianzhong.huang at i-soft.com.cn&gt; * * * gcc -shared -o libsublime-imfix.so sublime_imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC * LD_PRELOAD=./libsublime-imfix.so sublime_text */#include &lt;gtk/gtk.h&gt;#include &lt;gdk/gdkx.h&gt;typedef GdkSegment GdkRegionBox;struct _GdkRegion&#123; long size; long numRects; GdkRegionBox *rects; GdkRegionBox extents;&#125;;GtkIMContext *local_context;voidgdk_region_get_clipbox (const GdkRegion *region, GdkRectangle *rectangle)&#123; g_return_if_fail (region != NULL); g_return_if_fail (rectangle != NULL); rectangle-&gt;x = region-&gt;extents.x1; rectangle-&gt;y = region-&gt;extents.y1; rectangle-&gt;width = region-&gt;extents.x2 - region-&gt;extents.x1; rectangle-&gt;height = region-&gt;extents.y2 - region-&gt;extents.y1; GdkRectangle rect; rect.x = rectangle-&gt;x; rect.y = rectangle-&gt;y; rect.width = 0; rect.height = rectangle-&gt;height; //The caret width is 2; //Maybe sometimes we will make a mistake, but for most of the time, it should be the caret. if (rectangle-&gt;width == 2 &amp;&amp; GTK_IS_IM_CONTEXT(local_context)) &#123; gtk_im_context_set_cursor_location(local_context, rectangle); &#125;&#125;//this is needed, for example, if you input something in file dialog and return back the edit area//context will lost, so here we set it again.static GdkFilterReturn event_filter (GdkXEvent *xevent, GdkEvent *event, gpointer im_context)&#123; XEvent *xev = (XEvent *)xevent; if (xev-&gt;type == KeyRelease &amp;&amp; GTK_IS_IM_CONTEXT(im_context)) &#123; GdkWindow *win = g_object_get_data(G_OBJECT(im_context), \"window\"); if (GDK_IS_WINDOW(win)) &#123; gtk_im_context_set_client_window(im_context, win); &#125; &#125; return GDK_FILTER_CONTINUE;&#125;void gtk_im_context_set_client_window (GtkIMContext *context, GdkWindow *window)&#123; GtkIMContextClass *klass; g_return_if_fail (GTK_IS_IM_CONTEXT (context)); klass = GTK_IM_CONTEXT_GET_CLASS (context); if (klass-&gt;set_client_window) &#123; klass-&gt;set_client_window (context, window); &#125; if (!GDK_IS_WINDOW (window)) &#123; return; &#125; g_object_set_data(G_OBJECT(context), \"window\", window); int width = gdk_window_get_width(window); int height = gdk_window_get_height(window); if (width != 0 &amp;&amp; height != 0) &#123; gtk_im_context_focus_in(context); local_context = context; &#125; gdk_window_add_filter (window, event_filter, context);&#125; 在该文件所在目录下，编译 1gcc -shared -o libsublime-imfix.so sublime-imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC 编译后可以得到libsublime-imfix.so这个共享库 添加共享库到Sublime Text 3首先，测试一下是否在Sublime Text 3中可以输入中文 1LD_PRELOAD=./libsublime-imfix.so subl 如果可以正常使用搜狗输入法，进行接下来的配置 将libsublime-imfix.so拷贝到系统库的默认路径下： 1sudo cp libsublime-imfix.so /usr/lib 修改Sublime的执行文件/usr/bin/subl 12#!/bin/shLD_PRELOAD=/usr/lib/libsublime-imfix.so exec /opt/sublime_text/sublime_text &quot;$@&quot; 修改Sublime的快捷方式/usr/share/applications/sublime_text.desktop: 1234567# Exec=/opt/sublime_text/sublime_text %F# 修改为Exec=bash -c 'LD_PRELOAD=/usr/lib/libsublime-imfix.so /opt/sublime_text/sublime_text' %F# Exec=/opt/sublime_text/sublime_text -n# 修改为Exec=bash -c 'LD_PRELOAD=/usr/lib/libsublime-imfix.so /opt/sublime_text/sublime_text' -n 这样就可以在命令行subl和系统Application中的Sublime Text 3中输入中文了","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/tags/Ubuntu/"}]},{"title":"第一次审稿经验","slug":"170514-Manuscript-Review","date":"2017-05-14T08:34:42.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/14/170514-Manuscript-Review/","link":"","permalink":"https://kevinzjy.github.io/2017/05/14/170514-Manuscript-Review/","excerpt":"记录一下第一次审稿的经历233","text":"记录一下第一次审稿的经历233 前言最近在Briefings in Bioinformatics(BIB)上以二作身份和师兄发表了一篇文章（其实我啥也没做，就跑了几个软件= =)，然后投稿的时候注册了BIB的账号。不记得当时是不是选了啥选项，文章发表不就后就收到了一篇文章的Review Invitaion(没准是我们老板懒得申推荐给学生了)，反正在咨询老板后，选择了Agreed 在网站上重复确认后，会收到一封邮件 审稿过程在提交Review的页面，主要分为两大部分 Recommendation Accept: 接收，得多好的文章才能直接接收 = = Minor Revision: 需要较小改动， Major Revision: 需要较大改动，个人觉得可能一般遇到的都是这 Reject: 毫不留情，直接拒绝 Comments 这部分是主要对文章的评价部分,分为两小部分: Confidential Comments to the Editors: Use this space to transfer to the Editor the basis of your recommendation for acceptance or rejection. These comments will NOT be conveyed to the author. 直接对编辑说的话，并不会发送给作者，一般不用写(可能是用来写狠话的233) Comments to the Author: Use this space to convery specific feedback to the author on your recommendation. Please do NOT reference the Comments to Editor field as the author will not have direct access to those comments. 直接发送给作者的修改意见，在这部分，一般包括两部分： 对文章内容的大致总结归纳和审稿者对文章的总体评价 分条列出对文章中内容的修改意见 在填写好意见后，可以提交也可以暂时保存为草稿，最后提交审稿意见后，同样会收到提示邮件。 小插曲这次BIB审稿给了两周，中间正好遇到课题上比较忙，在写好这篇文章的审稿之后，还去问了老板，让老板补充了几条意见。最后写好的时候，已经过了给的截止日期了…… 其实中间还收到了两个 Gentle Reminder, 然而发邮件提醒也是拯救不了本拖延症患者的 于是在DDL最后一天给Editor发邮件申请拖到周末再提交Review 然后收到了编辑的回复 Not a problem. 看来大家都是拖延症，编辑已经习惯了:) P.S. 已经收到了编辑发给作者的Decision letter，现在坐等作者的Revision了","categories":[{"name":"Academic Life","slug":"Academic-Life","permalink":"https://kevinzjy.github.io/categories/Academic-Life/"}],"tags":[{"name":"Academic","slug":"Academic","permalink":"https://kevinzjy.github.io/tags/Academic/"}]},{"title":"MAC下使用Dropbox同步更新Hexo博客","slug":"170514-OSX-Dropbox","date":"2017-05-14T07:25:13.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/14/170514-OSX-Dropbox/","link":"","permalink":"https://kevinzjy.github.io/2017/05/14/170514-OSX-Dropbox/","excerpt":"在Mac上许多配置与Linux系统不大相同","text":"在Mac上许多配置与Linux系统不大相同 OS X上Hexo博客的搭建本人使用Dropbox同步Github pages目录，这样可以随时随地在设备上编辑博客并更新 在实际使用中，Ubuntu / Windows (Git bash) / Windows (WSL) 中使用Hexo十分完美，但是在OS X上，遇到了几个小问题 Dropbox在OS X中无法实时同步在Mac上修改文件，Windows下面会立即同步文件的更新, 但是反过来，Win下修改文件后，Mac下的Dropbox没有任何反应，必须要关闭后重新打开Dropbox才能开始同步 目前从官网下载了最新版本，暂时还没重现这个问题，版本号v25.4.28 Hexo deploy的时候提示Error: Cannot find module &#39;./build/Release/DTraceProviderBindings&#39;在Mac上，使用Nodejs安装了Hexo之后hexo deploy时，会出现上述报错，可能是因为Hexo版本过低，或者插件没有安装完全 1234npm install hexo --no-optional# 如果仍然不行npm uninstall hexo-cli -gnpm install hexo-cli -g","categories":[{"name":"OS X","slug":"OS-X","permalink":"https://kevinzjy.github.io/categories/OS-X/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kevinzjy.github.io/tags/Hexo/"},{"name":"MAC","slug":"MAC","permalink":"https://kevinzjy.github.io/tags/MAC/"}]},{"title":"Bash on Ubuntu on Windows的安装和配置 (二) Ubuntu软件推荐","slug":"170513-Ubuntu-Software","date":"2017-05-13T15:02:26.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/13/170513-Ubuntu-Software/","link":"","permalink":"https://kevinzjy.github.io/2017/05/13/170513-Ubuntu-Software/","excerpt":"记录一些Ubuntu上工具的安装和使用 Htop: 增强版的Top命令1sudo apt install htop Glances: 全面监控你的系统状态1sudo pip install glances[action,browser,cloud,cpuinfo,chart,docker,export,folders,gpu,ip,raid,snmp,web,wifi]","text":"记录一些Ubuntu上工具的安装和使用 Htop: 增强版的Top命令1sudo apt install htop Glances: 全面监控你的系统状态1sudo pip install glances[action,browser,cloud,cpuinfo,chart,docker,export,folders,gpu,ip,raid,snmp,web,wifi] Axel: 好用的多线程下载工具12sudo apt install axelaxel -n 4 -o ./ url Ack: 比grep更强大1sudo apt install ack-grep 附: 常用软件包在apt中的名称 Description Name pip (for python 2.7) python-pip pip (for python 3) python3-pip","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://kevinzjy.github.io/tags/Windows/"},{"name":"Software","slug":"Software","permalink":"https://kevinzjy.github.io/tags/Software/"},{"name":"Bash on Ubuntu","slug":"Bash-on-Ubuntu","permalink":"https://kevinzjy.github.io/tags/Bash-on-Ubuntu/"}]},{"title":"Windows下实现脚本开机自动启动","slug":"170513-Windows-Autostart","date":"2017-05-13T04:21:52.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/13/170513-Windows-Autostart/","link":"","permalink":"https://kevinzjy.github.io/2017/05/13/170513-Windows-Autostart/","excerpt":"实现Windows下程序的开机启动 如何实现Snipaste和自定义Hotkey的脚本开机自动启动在Windows资源管理器 -&gt; 查看 -&gt; 隐藏的项目，选中后，打开路径 C:\\Users\\kevin\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup 将需要开机自动启动的脚本放在这里即可","text":"实现Windows下程序的开机启动 如何实现Snipaste和自定义Hotkey的脚本开机自动启动在Windows资源管理器 -&gt; 查看 -&gt; 隐藏的项目，选中后，打开路径 C:\\Users\\kevin\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup 将需要开机自动启动的脚本放在这里即可","categories":[{"name":"Windows","slug":"windows","permalink":"https://kevinzjy.github.io/categories/windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://kevinzjy.github.io/tags/Windows/"}]},{"title":"Bash on Ubuntu on Windows的安装和配置 (一) WSL的安装和配置","slug":"170512-WSL","date":"2017-05-12T15:26:40.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/12/170512-WSL/","link":"","permalink":"https://kevinzjy.github.io/2017/05/12/170512-WSL/","excerpt":"记录基本的 Bash on Ubuntu on Windows (WSL) 的安装和配置过程参考官方说明 Step1: Bash on Ubuntu on Windows的下载和安装更新系统版本在 设置 -&gt; 系统 -&gt; 关于 中，查看系统版本号，系统必须为64位，版本号至少为14393.0，如果版本过低，检查更新至14393以上版本 打开开发者模式在 设置 -&gt; 更新和安全 -&gt; 针对开发人员 中，选中开发人员模式, 重启电脑 在 控制面板 -&gt; 程序 -&gt; 程序和功能 -&gt; 启动或关闭Windows功能 中，勾选适用于Linux的Windows子系统 打开命令行，输入bash, 阅读条款后输入”y”确认条款，下载安装Ubuntu sub system。安装完成后输入用户名和密码后，安装成功","text":"记录基本的 Bash on Ubuntu on Windows (WSL) 的安装和配置过程参考官方说明 Step1: Bash on Ubuntu on Windows的下载和安装更新系统版本在 设置 -&gt; 系统 -&gt; 关于 中，查看系统版本号，系统必须为64位，版本号至少为14393.0，如果版本过低，检查更新至14393以上版本 打开开发者模式在 设置 -&gt; 更新和安全 -&gt; 针对开发人员 中，选中开发人员模式, 重启电脑 在 控制面板 -&gt; 程序 -&gt; 程序和功能 -&gt; 启动或关闭Windows功能 中，勾选适用于Linux的Windows子系统 打开命令行，输入bash, 阅读条款后输入”y”确认条款，下载安装Ubuntu sub system。安装完成后输入用户名和密码后，安装成功 Step2: 更新Ubuntu版本检查Windows创意者更新，在Windows升级至1703版本后，WSL会自动升级至16.04 LTS 123# 手动查看Ubuntu版本号lsb_release -asudo do-release-upgrade # Manual upgrade to Ubuntu 16.04 Step3: 安装Ubuntu后进行的设置，参考: 新升级至Ubuntu 16.04 LTS后，打开Bash会提示 ‘To run a command as administrator (user “root”), use “sudo “. See “man sudo_root” for details.’，随便执行一个sudo命令，即可去掉该提示 1sudo -i 在Ubuntu升级后，sudo apt update可能会出现 “N: Ignoring file ‘50unattended-upgrades.ucf-dist’ in directory ‘/etc/apt/apt.conf.d/‘ as it has an invalid filename extension” 错误，将该旧版配置文件删除后 sudo apt update 即可解决 1sudo rm /etc/apt/apt.conf.d/50unattended-upgrades.ucf-dist &amp;&amp; sudo apt update 默认系统中提示音非常烦人，可以通过配置 $HOME/.inputrc 去除 1echo \"set bell-style none\" &gt; $HOME/.inputrc Ubuntu中默认安装的Vim版本有BUG在Insert模式中不能识别方向键,可以通过卸载并重新安装Vim解决 12sudo apt remove vimsudo apt install vim 去掉Vim中烦人的提示音 1echo \":set vb t_vb=\" &gt; $HOME/.vimrc 在执行需要联网的命令如apt时会提示 “sudo: unable to resolve host DESKTOP-2Q1PJM7”, 同时，在sudo apt update的时候会出现getaddrinfo.c错误: “../sysdeps/posix/getaddrinfo.c:2591: getaddrinfo: Assertion `(extension ({ const struct in6_addr __a = (const struct in6_addr ) (sin6-&gt;sin6_addr.in6_u.u6_addr32); a-&gt;in6_u.u6_addr32[0] == 0 &amp;&amp; a-&gt;in6_u.u6_addr32[1] == 0 &amp;&amp; a-&gt;in6_u.u6_addr32[2] == bswap_32 (0xffff); }))’ failed.” 123cat /etc/hostname # 查看本机hostnamesudo vi /etc/hosts127.0.0.1 DESKTOP-2Q1PJM7 # 改为你的hostname Note：目前我还没解决第二个Assertion报错，但是遇到报错时重复运行多次命令可以暂时解决 WSL系统中的文件在Windows下无法读取，但是Windows的磁盘分区已经自动挂载，如 C:/ -&gt; /mnt/c ，可以通过创建软链接的方式便于访问Windows下的文件 12ln -s /mnt/c Cln -s /mnt/d D 安装Git1sudo apt install git 这里我在Github上面设置了ssh-key登录 12ssh-keygen # 生产ssh-key后把pub key内容复制到github设置中git config --global user.email \"kevinzjy1997@gmail.com\" # 配置github账户 安装Cmder从官方网站下载Cmder，并在ConEmu下载ConEmu的更新，安装后覆盖至Cmder/vendor/conemu-maximus5，完成对ConEmu的更新 在Cmder中，直接运行Bash.exe时无法使用方向键。需要点击右下角 Settings -&gt; Startup -&gt; Tasks，新建任务 1C:\\Windows\\System32\\bash.exe ~ -cur_console:p:n # 直接进入~目录 即可在Bash中使用方向键, 如果使用 -cur_console:p1 会导致Vim中无法使用方向键 安装Bash-it对Bash环境进行美化在Windows 1703 创意者更新后，Cmder + zsh 环境配置下会出现光标前出现空格的Bug，目前暂未解决，因此使用Bash-it对默认的Bash环境进行美化 12git clone https://github.com/revans/bash-it.git ~/.bash_it~/.bash_it/install.sh 更改主题: 在 ~/.bashrc 中，把theme设为”simple” 12345678export BASH_IT_THEME='simple' # 主题配置export SCM_CHECK=true # Git插件配置export SCM_GIT_SHOW_DETAILS=true export SCM_GIT_SHOW_MINIMAL_INFO=true # 防止Git提示符乱码export TERM=xterm-256color # 设置Terminal类型，支持256色LC_ALL=en_US.UTF-8 安装X-server用来运行图形化程序默认情况下，WSL不能直接运行图形化程序，可以通过安装X-server并监听端口的方式解决 1export DISPLAY=:0 # 写入 .bashrc, 可以省去每次打开Bash后输入的麻烦 在Windows下，安装VcXsrv，运行VcXsrv监听:0端口 1Rstudio # 即可在Windows下启动Rstudio的图形化界面 不过用这种方法，打开的图形化界面太丑陋了，不能直视啊。。。 Tips: WSL系统内可以直接运行Windows命令1sublime_text.exe # 启动sublime text 但是不能在命令行直接对Linux下的文件进行编辑，应该是因为传递的文件名参数问题。这点其实可以通过一些方法解决，但是目前还没有这方面需求，懒得折腾了。。。 安装完这些，基本就可以在命令行和Bash on Ubuntu on Windows愉快地玩耍了~ Enjoy!","categories":[{"name":"Windows","slug":"windows","permalink":"https://kevinzjy.github.io/categories/windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://kevinzjy.github.io/tags/Windows/"},{"name":"Bash on Ubuntu","slug":"Bash-on-Ubuntu","permalink":"https://kevinzjy.github.io/tags/Bash-on-Ubuntu/"}]},{"title":"利用Sra-tools从NCBI下载SRA数据","slug":"170512-Sratoolkit","date":"2017-05-12T07:56:45.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/12/170512-Sratoolkit/","link":"","permalink":"https://kevinzjy.github.io/2017/05/12/170512-Sratoolkit/","excerpt":"Sra-tools的下载与安装Note: 旧版的Sratoolkit已经更新为Sra-tools 参考NCBI官方教程Wiki 12# Downloading SRA Toolkitwget \"http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz\"","text":"Sra-tools的下载与安装Note: 旧版的Sratoolkit已经更新为Sra-tools 参考NCBI官方教程Wiki 12# Downloading SRA Toolkitwget \"http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz\" 123# Unpacking the Toolkit tar -zxvf sratoolkit.current-centos_linux64.tar.gzcd sratoolkit.2.8.2-1-centos_linux64 12# Add to $PATHexport PATH=[sratoolkit_path]:$PATH 12# Test sratoolkitfastq-dump -X 5 -Z SRR390728 12# Configure vdb-config -i 在vdb-config的图形界面里更改[Default Import Path]，最好不要放在用户$HOME目录下，否则SRA文件可能会导致用户目录占用空间当某些情况下，vdb-config可能不能打开图形化界面，可以手动在配置文件中指定SRA文件的储存位置 12# 手动指定sra_pathecho '/repository/user/main/public/root = \"[sra_path]\"' &gt; $HOME/.ncbi/user-settings.mkfg 如何下载SRA文件一般情况下，我们下载的是paired-end reads，而默认的fastq-dump会把read1,read2解压在同一文件中，我们需要手动指定–split-3来分别获得read1和read2 12# Download DRX033310_1.fastq.gz, DRX033310_2.fastq.gzfastq-dump --split-3 --gzip SRR390728","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Bioinfomatics","slug":"Bioinfomatics","permalink":"https://kevinzjy.github.io/tags/Bioinfomatics/"},{"name":"Bioinformatic-Tools","slug":"Bioinformatic-Tools","permalink":"https://kevinzjy.github.io/tags/Bioinformatic-Tools/"}]},{"title":"shadowsocks教程","slug":"171123-Shadowsocks","date":"2017-05-12T07:56:45.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/05/12/171123-Shadowsocks/","link":"","permalink":"https://kevinzjy.github.io/2017/05/12/171123-Shadowsocks/","excerpt":"","text":"Windows下使用Shadowsocks配置Shadowsocks客户端下载Shadowsocks-4.0.6.zip 下载完成后，可以在习惯的位置创建一个新的文件夹，将Shadowsocks.exe解压到该目录下 右键以管理员身份运行Shadowsocks.exe，会在当前目录下自动生成下列文件（所以单独放在一个新文件夹下面比较好） - Shadowsocks.exe - statistics-config.json - user-wininet.json - ss_win_temp - gui-config.json (后面配置好节点信息后生成) 在服务器配置页面填入你的shadowsocks节点地址，端口，密码等信息，保存后点击添加，将节点配置保存到gui-config.json，记住配置中的代理端口(默认为1080) 保存后，右键任务栏中的shadowsocks图标（小飞机），启用系统代理，并设置为开机启动 系统代理模式 -&gt; PAC模式，PAC -&gt; 使用本地PAC，从GFWlist更新本地PAC 为浏览器设置代理Internet Explorer 和 Microsoft Edge (Win10) 无需进行额外设置，如果使用Chrome浏览器，可以使用SwithyOmega进行代理切换配置","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://kevinzjy.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://kevinzjy.github.io/tags/Windows/"},{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"OS X","slug":"OS-X","permalink":"https://kevinzjy.github.io/tags/OS-X/"}]},{"title":"Ubuntu下部署NAS","slug":"170430-Linux-NAS","date":"2017-04-30T08:18:15.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/04/30/170430-Linux-NAS/","link":"","permalink":"https://kevinzjy.github.io/2017/04/30/170430-Linux-NAS/","excerpt":"安装Ubuntu NAS","text":"安装Ubuntu NAS 开机自动挂载移动硬盘123sudo fdisk -lsudo umount /dev/sdb1sudo mkfs -t ext4 /dev/sdb1 使用bash-it 或者 zsh + oh-my-zsh123sudo apt updatesudo apt install zshsudo apt install git","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://kevinzjy.github.io/tags/Ubuntu/"},{"name":"NAS","slug":"NAS","permalink":"https://kevinzjy.github.io/tags/NAS/"}]},{"title":"Python中的多进程","slug":"170714-Python-Multiprocessing","date":"2017-03-29T04:55:17.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/03/29/170714-Python-Multiprocessing/","link":"","permalink":"https://kevinzjy.github.io/2017/03/29/170714-Python-Multiprocessing/","excerpt":"","text":"Python中的多进程使用 Multiprocessing进程池1234567891011from multiprocessing import Pooldef run_func(msg): print msgpool = Pool(4)jobs = []for i in range(4): jobs.append(pool.apply_async(run_func, (i, )))pool.close()pool.join() Multiprocessing线程池1234567891011from multiprocessing.dummpy import Pooldef run_func(msg): print msgpool = Pool(4)jobs = []for i in range(4): jobs.append(pool.apply_async(run_func, (i)))pool.close()pool.join()","categories":[{"name":"Python","slug":"python","permalink":"https://kevinzjy.github.io/categories/python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://kevinzjy.github.io/tags/Python/"},{"name":"Multiprocessing","slug":"Multiprocessing","permalink":"https://kevinzjy.github.io/tags/Multiprocessing/"}]},{"title":"Linux服务器使用技巧","slug":"170326-Linux-Tips","date":"2017-03-26T09:29:26.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/03/26/170326-Linux-Tips/","link":"","permalink":"https://kevinzjy.github.io/2017/03/26/170326-Linux-Tips/","excerpt":"记录一下Linux服务器使用时的小技巧 防止错误删除或重命名文件12alias rm=&apos;rm -i&apos;alias mv=&apos;mv -i&apos;","text":"记录一下Linux服务器使用时的小技巧 防止错误删除或重命名文件12alias rm=&apos;rm -i&apos;alias mv=&apos;mv -i&apos;","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"在Linux服务器上安装GCC，Boost和Cmake","slug":"170324-Install-gcc","date":"2017-03-24T13:46:27.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/03/24/170324-Install-gcc/","link":"","permalink":"https://kevinzjy.github.io/2017/03/24/170324-Install-gcc/","excerpt":"GCC的安装下载gcc-6.3.01234cd /panfs/home/zhao/zhangjy/software/src/gcc_src/wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-6.3.0/gcc-6.3.0.tar.gztar zxvf gcc-6.3.0.tar.gzcd gcc-6.3.0 安装依赖的mpfr, gmp和mpc等依赖工具1./contrib/download_prerequisites","text":"GCC的安装下载gcc-6.3.01234cd /panfs/home/zhao/zhangjy/software/src/gcc_src/wget http://ftp.tsukuba.wide.ad.jp/software/gcc/releases/gcc-6.3.0/gcc-6.3.0.tar.gztar zxvf gcc-6.3.0.tar.gzcd gcc-6.3.0 安装依赖的mpfr, gmp和mpc等依赖工具1./contrib/download_prerequisites 在新的目录下编译123mkdir -p /panfs/home/zhao/zhangjy/software/src/gcc_buildcd /panfs/home/zhao/zhangjy/software/src/gcc_build/panfs/home/zhao/zhangjy/software/src/gcc_src/gcc-6.3.0/configure --prefix=/panfs/home/zhao/zhangjy/software/gcc --disable-multilib 修改环境变量12echo $LD_LIBRARY_PATHecho $LIBRARY_PATH 如果输出的$LD_LIBRARY_PATH或LIBRARY_PATH是以:结尾,比如: 1/public/software/intel/composer_xe_2011_sp1.7.256/compiler/lib/intel64:/public/software/intel/composer_xe_2011_sp1.7.256/mkl/lib/intel64: 需要去掉结尾处的:，否则make时候会报错 1export LIBRARY_PATH=/public/software/intel/composer_xe_2011_sp1.7.256/compiler/lib/intel64:/public/software/intel/composer_xe_2011_sp1.7.256/mkl/lib/intel64 安装GCC12make -j 10 # make in 10 threadsmake install 添加新安装的GCC到环境变量Note: $LD_LIBRARY_PATH中要加入两个目录 123export PATH=/panfs/home/zhao/zhangjy/software/gcc/bin:$PATHexport LD_LIBRARY_PATH=/panfs/home/zhao/zhangjy/software/gcc/lib/gcc/x86_64-pc-linux-gnu/6.3.0:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/panfs/home/zhao/zhangjy/software/gcc/lib64:$LD_LIBRARY_PATH 当安装其他软件时，指定调用新版的GCC123export CC=/panfs/home/zhao/zhangjy/software/gcc/bin/gccexport CXX=/panfs/home/zhao/zhangjy/software/gcc/bin/g++cmake $YOUR_PATH -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR Boost的安装下载Boost123wget https://nchc.dl.sourceforge.net/project/boost/boost/1.63.0/boost_1_63_0.tar.gztar zxvf boost_1_63_0.tar.gzcd boost_1_63_0 安装Boost1sh ./bootstrap.sh 指定boost安装目录和include, lib文件夹的位置1./bjam -j 4 --prefix=/panfs/home/zhao/zhangjy/software/boost --includedir=/panfs/home/zhao/zhangjy/software/boost --libdir=/panfs/home/zhao/zhangjy/software/boost install 添加到环境变量12export PATH=/panfs/home/zhao/zhangjy/software/boost/boost:$PATHexport LD_LIBRARY_PATH=/panfs/home/zhao/zhangjy/software/boost/lib:$LD_LIBRARY_PATH 安装Cmake下载Cmake123wget https://cmake.org/files/v3.7/cmake-3.7.2.tar.gz --no-check-certificatetar zxvf cmake-3.7.2.tar.gzcd cmake-3.7.2 安装Cmake12./bootstrap --prefix=/panfs/home/zhao/zhangjy/software/cmakegmake &amp;&amp; gmake install 添加到环境变量1export PATH=/panfs/home/zhao/zhangjy/software/cmake/bin:$PATH","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Software","slug":"Software","permalink":"https://kevinzjy.github.io/tags/Software/"},{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]},{"title":"在Windows下使用Github pages + Hexo搭建个人博客","slug":"170324-Github-pages-Hexo","date":"2017-03-24T13:16:34.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/03/24/170324-Github-pages-Hexo/","link":"","permalink":"https://kevinzjy.github.io/2017/03/24/170324-Github-pages-Hexo/","excerpt":"依赖工具在Windows下安装Git + Node.js + Cmder 安装Git下载Git，下载地址安装时选择添加Git到$PATH 配置Cmder安装Cmder, 在Cmder中添加{git bash}: 12Task parameters: /icon \"C:\\Program Files\\Git\\git-bash.exe\"Commands: \"C:\\Program Files\\Git\\bin\\sh.exe\" --login -i","text":"依赖工具在Windows下安装Git + Node.js + Cmder 安装Git下载Git，下载地址安装时选择添加Git到$PATH 配置Cmder安装Cmder, 在Cmder中添加{git bash}: 12Task parameters: /icon \"C:\\Program Files\\Git\\git-bash.exe\"Commands: \"C:\\Program Files\\Git\\bin\\sh.exe\" --login -i 安装Node.js下载Node.js, 下载地址 安装Hexo123456789101112npm install hexo-cli -gmkdir -p /c/Users/kevin/Dropbox/git/Kevinzjy.github.iocd /c/Users/kevin/Dropbox/git/Kevinzjy.github.iohexo initnpm installnpm install hexo-deployer-git --save #安装git插件hexo clean hexo g # generate hexo s # start 编辑_congif.yml 1234deploy: type: git repo: git@github.com:Kevinzjy/Kevinzjy.github.io.git branch: master deploy到github 1hexo d # deployment 当出现warning: LD will be replaced by CRLF in …时，删除hexo文件夹下面的.deplo_git文件夹 1git config --global core.autocrlf false Hexo主题配置12git clone https://github.com/iissnan/hexo-theme-next themes/nextrm -rf ./themes/next/.git # 删除.git目录，防止github build时出错 编辑_config.yml，将theme改为next NexT主题配置坑 附：Ubuntu中安装nodejs123wget https://nodejs.org/dist/v6.10.3/node-v6.10.3-linux-x64.tar.xztar xvf node-v6.10.3-linux-x64.tar.xzmv node-v6.10.3-linux-x64 ../node-v6.10.3 编辑.zshrc文件，加入nodejs的路径 12export PATH=/home/zhangjy/software/node-v6.10.3/bin:$PATHnpm install hexo-cli -g","categories":[{"name":"Windows","slug":"windows","permalink":"https://kevinzjy.github.io/categories/windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://kevinzjy.github.io/tags/Windows/"},{"name":"Software","slug":"Software","permalink":"https://kevinzjy.github.io/tags/Software/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kevinzjy.github.io/tags/Hexo/"}]},{"title":"在Linux服务器上安装R","slug":"170324-Install-R","date":"2017-03-24T12:08:28.000Z","updated":"2020-12-26T08:24:26.689Z","comments":true,"path":"2017/03/24/170324-Install-R/","link":"","permalink":"https://kevinzjy.github.io/2017/03/24/170324-Install-R/","excerpt":"设置环境变量12export R_HOME=/panfs/home/zhao/zhangjy/software/Rexport R_SRC=/panfs/home/zhao/zhangjy/pacakges 安装Dependencieszlib123456cd $R_SRCwget https://nchc.dl.sourceforge.net/project/libpng/zlib/1.2.11/zlib-1.2.11.tar.gztar zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11 ./configure --prefix=$R_HOMEmake &amp;&amp; make install","text":"设置环境变量12export R_HOME=/panfs/home/zhao/zhangjy/software/Rexport R_SRC=/panfs/home/zhao/zhangjy/pacakges 安装Dependencieszlib123456cd $R_SRCwget https://nchc.dl.sourceforge.net/project/libpng/zlib/1.2.11/zlib-1.2.11.tar.gztar zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11 ./configure --prefix=$R_HOMEmake &amp;&amp; make install bzip212345cd $R_SRCwget http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz -O ./bzip2-1.0.6.tar.gztar zxvf bzip2-1.0.6.tar.gzcd bzip2-1.0.6make &amp;&amp; make install PREFIX=$R_HOME liblzma123456cd $R_SRCwget --no-check-certificate http://tukaani.org/xz/xz-5.2.3.tar.gz tar zxvf xz-5.2.3.tar.gzcd xz-5.2.3./configure --prefix=$R_HOMEmake &amp;&amp; make install pcre123456cd $R_SRCwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.40.tar.gztar zxvf pcre-8.40.tar.gzcd pcre-8.40./configure --enable-utf8 --prefix=$R_HOMEmake &amp;&amp; make install libcurl123456cd $R_SRCwget --no-check-certificate https://curl.haxx.se/download/curl-7.53.1.tar.gztar zxvf curl-7.53.1.tar.gzcd curl-7.53.1./configure --prefix=$R_HOMEmake &amp;&amp; make install 配置R安装环境1234export LD_LIBRARY_PATH=$R_HOME/include:$LD_LIBRARY_PATHexport PATH=$R_HOME/bin:$PATHexport CFLAGS=\"-I$R_HOME/include\"export LDFLAGS=\"-L$R_HOME/lib\" 编译和安装R123456cd $R_SRCwget https://mirrors.tuna.tsinghua.edu.cn/CRAN/src/base/R-3/R-3.3.3.tar.gztar zxvf R-3.3.3.tar.gzcd R-3.3.3./configure --prefix=$R_HOMEmake &amp;&amp; make install 修改.zshrc或者.bashrc在rc文件中增加如下内容 123export PATH=/panfs/home/zhao/zhangjy/software/R/bin:$PATHexport LD_LIBRARY_PATH=/panfs/home/zhao/zhangjy/software/R/lib:$LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/panfs/home/zhao/zhangjy/software/R/include:$LD_LIBRARY_PATH","categories":[{"name":"Linux","slug":"linux","permalink":"https://kevinzjy.github.io/categories/linux/"}],"tags":[{"name":"Software","slug":"Software","permalink":"https://kevinzjy.github.io/tags/Software/"},{"name":"Linux","slug":"Linux","permalink":"https://kevinzjy.github.io/tags/Linux/"},{"name":"Server","slug":"Server","permalink":"https://kevinzjy.github.io/tags/Server/"}]}]}